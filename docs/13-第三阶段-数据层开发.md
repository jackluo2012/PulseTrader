# 第三阶段：数据层开发

> **目标**: 实现多数据源统一接入和管理
> **预计时间**: 4-5天
> **提交标记**: `data-layer-complete`
> **前置条件**: 已完成[第二阶段基础框架](./12-第二阶段-基础框架.md)

## 📋 步骤概览

1. [✅] Tushare 数据源实现
2. [ ] akshare 数据源集成
3. [ ] pytdx 实时行情接口
4. [ ] 数据缓存系统
5. [ ] 数据质量验证
6. [ ] 统一数据接口

---

## 步骤 1: Tushare 数据源实现

### 1.1 配置 Tushare

首先，您需要获取 Tushare Pro Token：

1. 注册 [Tushare Pro](https://tushare.pro/) 账户
2. 完成实名认证
3. 获取 API Token

配置环境变量：

```bash
# 编辑 config/.env 文件
cp config/.env.example config/.env

# 添加您的 Tushare Token
echo "TUSHARE_TOKEN=your_actual_token_here" >> config/.env
```

### 1.2 实现 Tushare 数据源

创建 `engine/src/data/tushare.rs`:

```rust
// engine/src/data/tushare.rs

use super::{DataSource, DataSourceConfig};
use crate::{KlineData, TickData, DataType, Result, PulseTraderError};
use async_trait::async_trait;
use chrono::{DateTime, Utc, TimeZone, NaiveDateTime};
use reqwest::Client;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

/// Tushare Pro 数据源
pub struct TushareDataSource {
    client: Client,
    token: String,
    base_url: String,
    rate_limiter: std::sync::Arc<tokio::sync::Semaphore>,
}

/// Tushare API 响应结构
#[derive(Debug, Deserialize)]
struct TushareResponse {
    request_id: String,
    code: i32,
    msg: Option<String>,
    data: TushareData,
}

#[derive(Debug, Deserialize)]
struct TushareData {
    fields: Vec<String>,
    items: Vec<Vec<serde_json::Value>>,
}

/// K线数据项
#[derive(Debug, Deserialize)]
struct TushareKlineItem {
    ts_code: String,
    trade_date: String,
    open: f64,
    high: f64,
    low: f64,
    close: f64,
    pre_close: f64,
    change: f64,
    pct_chg: f64,
    vol: f64,
    amount: f64,
}

impl TushareDataSource {
    pub fn new(config: DataSourceConfig) -> Self {
        let token = config.params
            .get("token")
            .and_then(|v| v.as_str())
            .unwrap_or("")
            .to_string();

        let base_url = config.params
            .get("base_url")
            .and_then(|v| v.as_str())
            .unwrap_or("https://api.tushare.pro")
            .to_string();

        let rate_limit = config.rate_limit.unwrap_or(200); // 默认每分钟200次
        let rate_limiter = std::sync::Arc::new(tokio::sync::Semaphore::new(
            (rate_limit / 60).max(1) as usize
        ));

        Self {
            client: Client::new(),
            token,
            base_url,
            rate_limiter,
        }
    }

    /// 执行 Tushare API 请求
    async fn request_api(&self, api_name: &str, params: HashMap<String, serde_json::Value>) -> Result<TushareResponse> {
        // 速率限制
        let _permit = self.rate_limiter.acquire().await.unwrap();

        let mut request_params = params;
        request_params.insert("token".to_string(), serde_json::Value::String(self.token.clone()));
        request_params.insert("api_name".to_string(), serde_json::Value::String(api_name.to_string()));

        let response = self.client
            .post(&format!("{}/v1/", self.base_url))
            .json(&request_params)
            .send()
            .await?;

        if !response.status().is_success() {
            return Err(PulseTraderError::NetworkError {
                source: reqwest::Error::from(response.error_for_status().unwrap_err()),
            });
        }

        let tushare_response: TushareResponse = response.json().await?;

        if tushare_response.code != 0 {
            return Err(PulseTraderError::DataError {
                message: tushare_response.msg.unwrap_or_else(|| "Unknown Tushare error".to_string()),
            });
        }

        Ok(tushare_response)
    }

    /// 转换 Tushare 日期格式
    fn parse_tushare_date(&self, date_str: &str) -> Result<DateTime<Utc>> {
        let naive_date = NaiveDateTime::parse_from_str(date_str, "%Y%m%d %H:%M:%S")
            .or_else(|_| NaiveDateTime::parse_from_str(&format!("{} 09:00:00", date_str), "%Y%m%d %H:%M:%S"))?;

        Ok(Utc.from_utc_datetime(&naive_date))
    }

    /// 获取股票基本信息
    async fn get_stock_basic(&self) -> Result<Vec<String>> {
        let mut params = HashMap::new();
        params.insert("exchange".to_string(), serde_json::Value::String("SSE,SZSE".to_string()));
        params.insert("list_status".to_string(), serde_json::Value::String("L".to_string()));

        let response = self.request_api("stock_basic", params).await?;
        let mut symbols = Vec::new();

        for item in response.data.items {
            if let (Some(ts_code), Some(list_status)) = (item.get(0), item.get(5)) {
                if let (Some(ts_code_str), Some("L")) = (ts_code.as_str(), list_status.as_str()) {
                    symbols.push(ts_code_str.to_string());
                }
            }
        }

        Ok(symbols)
    }
}

#[async_trait]
impl DataSource for TushareDataSource {
    async fn get_kline_data(
        &self,
        symbol: &str,
        data_type: DataType,
        start: DateTime<Utc>,
        end: DateTime<Utc>,
    ) -> Result<Vec<KlineData>> {
        let api_name = match data_type {
            DataType::Daily => "daily",
            DataType::Minute1 => "daily",  // Tushare 免费版主要支持日线
            _ => return Err(PulseTraderError::DataError {
                message: format!("不支持的数据类型: {:?}", data_type),
            }),
        };

        let mut params = HashMap::new();
        params.insert("ts_code".to_string(), serde_json::Value::String(symbol.to_string()));
        params.insert("start_date".to_string(), serde_json::Value::String(
            start.format("%Y%m%d").to_string()
        ));
        params.insert("end_date".to_string(), serde_json::Value::String(
            end.format("%Y%m%d").to_string()
        ));

        let response = self.request_api(api_name, params).await?;
        let mut kline_data = Vec::new();

        // 解析字段名
        let fields: HashMap<String, usize> = response.data.fields
            .into_iter()
            .enumerate()
            .map(|(i, field)| (field, i))
            .collect();

        for item in response.data.items {
            // 提取各个字段的值
            let get_value = |field: &str| -> Option<f64> {
                fields.get(field)
                    .and_then(|&idx| item.get(idx))
                    .and_then(|v| v.as_str())
                    .and_then(|s| s.parse().ok())
            };

            let get_string = |field: &str| -> Option<String> {
                fields.get(field)
                    .and_then(|&idx| item.get(idx))
                    .and_then(|v| v.as_str())
                    .map(|s| s.to_string())
            };

            if let (Some(ts_code), Some(trade_date), Some(open), Some(high), Some(low), Some(close), Some(vol), Some(amount)) = (
                get_string("ts_code"),
                get_string("trade_date"),
                get_value("open"),
                get_value("high"),
                get_value("low"),
                get_value("close"),
                get_value("vol"),
                get_value("amount"),
            ) {
                let timestamp = self.parse_tushare_date(&trade_date)?;

                let kline = KlineData::new(
                    ts_code,
                    timestamp,
                    open,
                    high,
                    low,
                    close,
                    vol * 100.0,  // Tushare 返回的是手数
                    amount * 1000.0, // Tushare 返回的是千元
                );

                if kline.is_valid() {
                    kline_data.push(kline);
                }
            }
        }

        // 按时间排序
        kline_data.sort_by_key(|k| k.timestamp);
        Ok(kline_data)
    }

    async fn get_tick_data(&self, _symbol: &str) -> Result<Vec<TickData>> {
        // Tushare 免费版不支持实时tick数据
        Err(PulseTraderError::DataError {
            message: "Tushare 免费版不支持实时tick数据".to_string(),
        })
    }

    async fn get_stock_list(&self) -> Result<Vec<String>> {
        self.get_stock_basic().await
    }

    async fn health_check(&self) -> Result<bool> {
        // 尝试获取一只股票的基本信息
        let response = self.request_api("stock_basic", HashMap::new()).await;
        Ok(response.is_ok())
    }
}
```

### 1.3 更新数据源模块

编辑 `engine/src/data/mod.rs`:

```rust
// engine/src/data/mod.rs

pub mod source;
pub mod storage;
pub mod tushare;

pub use source::{DataSource, DataSourceConfig};
pub use storage::DataStorage;
pub use tushare::TushareDataSource;

use crate::{KlineData, TickData, DataType, Result};
use async_trait::async_trait;
use std::collections::HashMap;

// ... 其余代码保持不变 ...
```

### 1.4 添加 Cargo 依赖

编辑 `engine/Cargo.toml`:

```toml
# 在 [dependencies] 部分添加
async-trait = "0.1"
csv = "1.3"
rand = "0.8"
serde_json = "1.0"
```

---

## 步骤 2: akshare 数据源集成

### 2.1 创建 Python 数据源管理器

创建 `python/pulse_trader/data_sources/__init__.py`:

```python
# python/pulse_trader/data_sources/__init__.py

"""
数据源模块
"""

from .base import BaseDataSource
from .tushare_source import TushareSource
from .akshare_source import AkshareSource
from .pytdx_source import PytdxSource
from .manager import DataSourceManager

__all__ = [
    "BaseDataSource",
    "TushareSource",
    "AkshareSource",
    "PytdxSource",
    "DataSourceManager",
]
```

创建 `python/pulse_trader/data_sources/base.py`:

```python
# python/pulse_trader/data_sources/base.py

"""
数据源基类
"""

from abc import ABC, abstractmethod
from typing import List, Optional, Union, Dict, Any
from datetime import datetime, date
import pandas as pd
from ..exceptions import DataError, NetworkError


class BaseDataSource(ABC):
    """数据源基类"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.name = self.__class__.__name__
        self._initialized = False

    @abstractmethod
    async def initialize(self) -> bool:
        """初始化数据源"""
        pass

    @abstractmethod
    async def get_kline_data(
        self,
        symbol: str,
        period: str = "daily",
        start_date: Union[str, date, datetime] = None,
        end_date: Union[str, date, datetime] = None,
        adjust: str = "qfq"
    ) -> pd.DataFrame:
        """
        获取K线数据

        Args:
            symbol: 股票代码
            period: 周期 (daily, weekly, monthly, 1min, 5min, 15min, 30min, 60min)
            start_date: 开始日期
            end_date: 结束日期
            adjust: 复权类型 (qfq-前复权, hfq-后复权, none-不复权)

        Returns:
            K线数据 DataFrame
        """
        pass

    @abstractmethod
    async def get_realtime_quote(self, symbols: List[str]) -> pd.DataFrame:
        """获取实时行情"""
        pass

    @abstractmethod
    async def get_stock_list(self, market: str = "A") -> pd.DataFrame:
        """
        获取股票列表

        Args:
            market: 市场类型 (A-A股, HK-港股, US-美股)

        Returns:
            股票列表 DataFrame
        """
        pass

    @abstractmethod
    async def health_check(self) -> bool:
        """健康检查"""
        pass

    def _validate_symbol(self, symbol: str) -> str:
        """验证并标准化股票代码"""
        if not symbol:
            raise DataError("股票代码不能为空")

        # 标准化格式
        symbol = symbol.upper().strip()

        # 如果没有交易所后缀，自动添加
        if '.' not in symbol:
            if symbol.startswith('0') or symbol.startswith('3'):
                symbol += '.SZ'
            elif symbol.startswith('6'):
                symbol += '.SH'
            elif symbol.startswith('8') or symbol.startswith('4'):
                symbol += '.BJ'

        return symbol

    def _validate_date_range(self, start_date: Union[str, date, datetime],
                           end_date: Union[str, date, datetime]) -> tuple:
        """验证日期范围"""
        if isinstance(start_date, str):
            start_date = pd.to_datetime(start_date).date()
        elif isinstance(start_date, datetime):
            start_date = start_date.date()

        if isinstance(end_date, str):
            end_date = pd.to_datetime(end_date).date()
        elif isinstance(end_date, datetime):
            end_date = end_date.date()

        if start_date >= end_date:
            raise DataError("开始日期必须早于结束日期")

        return start_date, end_date

    def _standardize_kline_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """标准化K线数据列名"""
        column_mapping = {
            'trade_date': 'timestamp',
            'date': 'timestamp',
            'time': 'timestamp',
            'open': 'open',
            'high': 'high',
            'low': 'low',
            'close': 'close',
            'volume': 'volume',
            'vol': 'volume',
            'amount': 'amount',
            'turnover': 'amount',
            'pct_chg': 'change_pct',
            'pct_change': 'change_pct',
        }

        # 重命名列
        df = df.rename(columns=column_mapping)

        # 确保必需的列存在
        required_columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume']
        missing_columns = [col for col in required_columns if col not in df.columns]

        if missing_columns:
            raise DataError(f"数据缺少必需的列: {missing_columns}")

        # 按时间排序
        if 'timestamp' in df.columns:
            df = df.sort_values('timestamp').reset_index(drop=True)

        return df

    async def __aenter__(self):
        """异步上下文管理器入口"""
        if not self._initialized:
            await self.initialize()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """异步上下文管理器出口"""
        # 清理资源
        pass
```

创建 `python/pulse_trader/data_sources/akshare_source.py`:

```python
# python/pulse_trader/data_sources/akshare_source.py

"""
akshare 数据源实现
"""

import asyncio
from typing import List, Union, Dict, Any
from datetime import datetime, date
import pandas as pd
import akshare as ak
from .base import BaseDataSource
from ..exceptions import DataError, NetworkError
from ..utils import get_logger

logger = get_logger(__name__)


class AkshareSource(BaseDataSource):
    """akshare 数据源"""

    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.cache_enabled = config.get('cache_enabled', True)
        self.timeout = config.get('timeout', 30)

    async def initialize(self) -> bool:
        """初始化 akshare"""
        try:
            # 测试 akshare 是否可用
            test_df = ak.tool_trade_date_hist_sina()
            if not test_df.empty:
                self._initialized = True
                logger.info("akshare 数据源初始化成功")
                return True
            else:
                logger.error("akshare 初始化测试失败")
                return False
        except Exception as e:
            logger.error(f"akshare 初始化失败: {e}")
            return False

    async def get_kline_data(
        self,
        symbol: str,
        period: str = "daily",
        start_date: Union[str, date, datetime] = None,
        end_date: Union[str, date, datetime] = None,
        adjust: str = "qfq"
    ) -> pd.DataFrame:
        """获取K线数据"""
        try:
            # 验证和标准化参数
            symbol = self._validate_symbol(symbol)

            if start_date is None:
                start_date = (datetime.now() - pd.Timedelta(days=365)).date()
            if end_date is None:
                end_date = datetime.now().date()

            start_date, end_date = self._validate_date_range(start_date, end_date)

            # 转换 akshare 格式的股票代码
            ak_symbol = self._convert_symbol_for_akshare(symbol)

            # 选择对应的 akshare 接口
            if period == "daily":
                df = await self._get_daily_data(ak_symbol, start_date, end_date, adjust)
            elif period in ["1min", "5min", "15min", "30min", "60min"]:
                df = await self._get_minute_data(ak_symbol, period, start_date, end_date)
            else:
                raise DataError(f"不支持的时间周期: {period}")

            if df.empty:
                logger.warning(f"未获取到股票 {symbol} 的数据")
                return pd.DataFrame()

            # 添加股票代码列
            df['symbol'] = symbol

            # 标准化列名
            df = self._standardize_kline_columns(df)

            logger.info(f"成功获取 {symbol} K线数据，共 {len(df)} 条记录")
            return df

        except Exception as e:
            logger.error(f"获取K线数据失败: {e}")
            raise DataError(f"获取K线数据失败: {e}")

    async def _get_daily_data(self, symbol: str, start_date: date, end_date: date, adjust: str) -> pd.DataFrame:
        """获取日线数据"""
        try:
            # 在线程池中执行同步的 akshare 调用
            loop = asyncio.get_event_loop()

            if adjust == "qfq":
                # 前复权数据
                df = await loop.run_in_executor(
                    None,
                    lambda: ak.stock_zh_a_hist(
                        symbol=symbol,
                        period="daily",
                        start_date=start_date.strftime("%Y%m%d"),
                        end_date=end_date.strftime("%Y%m%d"),
                        adjust="qfq"
                    )
                )
            else:
                # 不复权数据
                df = await loop.run_in_executor(
                    None,
                    lambda: ak.stock_zh_a_hist(
                        symbol=symbol,
                        period="daily",
                        start_date=start_date.strftime("%Y%m%d"),
                        end_date=end_date.strftime("%Y%m%d"),
                        adjust=""
                    )
                )

            return df

        except Exception as e:
            logger.error(f"获取日线数据失败: {e}")
            raise

    async def _get_minute_data(self, symbol: str, period: str, start_date: date, end_date: date) -> pd.DataFrame:
        """获取分钟线数据"""
        try:
            loop = asyncio.get_event_loop()

            # akshare 的分钟线数据接口
            df = await loop.run_in_executor(
                None,
                lambda: ak.stock_zh_a_hist_min_em(
                    symbol=symbol,
                    period=period,
                    start_date=start_date.strftime("%Y%m%d %H:%M:%S"),
                    end_date=end_date.strftime("%Y%m%d %H:%M:%S")
                )
            )

            return df

        except Exception as e:
            logger.error(f"获取分钟线数据失败: {e}")
            raise

    async def get_realtime_quote(self, symbols: List[str]) -> pd.DataFrame:
        """获取实时行情"""
        try:
            if not symbols:
                return pd.DataFrame()

            loop = asyncio.get_event_loop()
            quotes = []

            for symbol in symbols:
                symbol = self._validate_symbol(symbol)
                ak_symbol = self._convert_symbol_for_akshare(symbol)

                try:
                    quote = await loop.run_in_executor(
                        None,
                        lambda: ak.stock_zh_a_spot_em()
                    )

                    # 筛选指定股票的数据
                    stock_quote = quote[quote['代码'] == ak_symbol[:-3]]  # 去掉交易所后缀
                    if not stock_quote.empty:
                        quotes.append(stock_quote.iloc[0].to_dict())

                except Exception as e:
                    logger.warning(f"获取 {symbol} 实时行情失败: {e}")
                    continue

            if quotes:
                df = pd.DataFrame(quotes)
                # 标准化列名
                df = df.rename(columns={
                    '代码': 'symbol',
                    '最新价': 'price',
                    '涨跌幅': 'change_pct',
                    '成交量': 'volume',
                    '成交额': 'amount',
                    '开盘价': 'open',
                    '最高价': 'high',
                    '最低价': 'low',
                    '昨收': 'pre_close'
                })
                return df
            else:
                return pd.DataFrame()

        except Exception as e:
            logger.error(f"获取实时行情失败: {e}")
            raise NetworkError(f"获取实时行情失败: {e}")

    async def get_stock_list(self, market: str = "A") -> pd.DataFrame:
        """获取股票列表"""
        try:
            loop = asyncio.get_event_loop()

            if market == "A":
                # 获取A股列表
                df = await loop.run_in_executor(None, lambda: ak.stock_zh_a_spot_em())

                # 标准化格式
                df = df[['代码', '名称']].copy()
                df.columns = ['symbol', 'name']

                # 添加交易所后缀
                def add_exchange_suffix(code):
                    if code.startswith('0') or code.startswith('3'):
                        return f"{code}.SZ"
                    elif code.startswith('6'):
                        return f"{code}.SH"
                    elif code.startswith('8') or code.startswith('4'):
                        return f"{code}.BJ"
                    return code

                df['symbol'] = df['symbol'].apply(add_exchange_suffix)
                return df

            else:
                raise DataError(f"不支持的市场类型: {market}")

        except Exception as e:
            logger.error(f"获取股票列表失败: {e}")
            raise DataError(f"获取股票列表失败: {e}")

    async def health_check(self) -> bool:
        """健康检查"""
        try:
            loop = asyncio.get_event_loop()
            # 尝试获取交易日历
            df = await loop.run_in_executor(None, lambda: ak.tool_trade_date_hist_sina())
            return not df.empty
        except Exception as e:
            logger.error(f"akshare 健康检查失败: {e}")
            return False

    def _convert_symbol_for_akshare(self, symbol: str) -> str:
        """转换为 akshare 格式的股票代码"""
        # akshare 使用不带交易所后缀的6位代码
        if '.' in symbol:
            return symbol.split('.')[0]
        return symbol

    def __str__(self) -> str:
        return f"AkshareSource(initialized={self._initialized})"


# akshare 数据源注册
def get_akshare_source(config: Dict[str, Any]) -> AkshareSource:
    """获取 akshare 数据源实例"""
    return AkshareSource(config)
```

### 2.2 创建 Tushare Python 数据源

创建 `python/pulse_trader/data_sources/tushare_source.py`:

```python
# python/pulse_trader/data_sources/tushare_source.py

"""
Tushare 数据源实现
"""

import asyncio
from typing import List, Union, Dict, Any
from datetime import datetime, date
import pandas as pd
import tushare as ts
from .base import BaseDataSource
from ..exceptions import DataError, NetworkError
from ..utils import get_logger

logger = get_logger(__name__)


class TushareSource(BaseDataSource):
    """Tushare Pro 数据源"""

    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.token = config.get('token', '')
        self.pro_api = config.get('pro_api', 'https://api.tushare.pro')
        self.rate_limit = config.get('rate_limit', 200)  # 每分钟请求次数
        self._ts_api = None
        self._request_count = 0
        self._last_reset_time = datetime.now()

    async def initialize(self) -> bool:
        """初始化 Tushare"""
        try:
            if not self.token:
                raise DataError("Tushare token 未配置")

            # 设置 token
            ts.set_token(self.token)
            self._ts_api = ts.pro_api(self.pro_api)

            # 测试连接
            test_result = await self._test_connection()
            if test_result:
                self._initialized = True
                logger.info("Tushare 数据源初始化成功")
                return True
            else:
                logger.error("Tushare 连接测试失败")
                return False

        except Exception as e:
            logger.error(f"Tushare 初始化失败: {e}")
            return False

    async def _test_connection(self) -> bool:
        """测试连接"""
        try:
            loop = asyncio.get_event_loop()
            # 尝试获取交易日期
            df = await loop.run_in_executor(None, lambda: self._ts_api.trade_cal(exchange='SSE', start_date='20240101', end_date='20240105'))
            return not df.empty
        except Exception as e:
            logger.error(f"Tushare 连接测试失败: {e}")
            return False

    async def _rate_limit_check(self):
        """速率限制检查"""
        now = datetime.now()

        # 每分钟重置计数器
        if (now - self._last_reset_time).seconds >= 60:
            self._request_count = 0
            self._last_reset_time = now

        # 检查是否超过限制
        if self._request_count >= self.rate_limit:
            wait_time = 60 - (now - self._last_reset_time).seconds
            if wait_time > 0:
                logger.warning(f"达到速率限制，等待 {wait_time} 秒")
                await asyncio.sleep(wait_time)
                self._request_count = 0
                self._last_reset_time = datetime.now()

        self._request_count += 1

    async def get_kline_data(
        self,
        symbol: str,
        period: str = "daily",
        start_date: Union[str, date, datetime] = None,
        end_date: Union[str, date, datetime] = None,
        adjust: str = "qfq"
    ) -> pd.DataFrame:
        """获取K线数据"""
        try:
            if not self._initialized:
                raise DataError("数据源未初始化")

            # 验证参数
            symbol = self._validate_symbol(symbol)

            if start_date is None:
                start_date = (datetime.now() - pd.Timedelta(days=365)).date()
            if end_date is None:
                end_date = datetime.now().date()

            start_date, end_date = self._validate_date_range(start_date, end_date)

            # 速率限制
            await self._rate_limit_check()

            # 获取数据
            loop = asyncio.get_event_loop()

            df = await loop.run_in_executor(
                None,
                lambda: self._ts_api.daily(
                    ts_code=symbol,
                    start_date=start_date.strftime("%Y%m%d"),
                    end_date=end_date.strftime("%Y%m%d")
                )
            )

            if df.empty:
                logger.warning(f"未获取到股票 {symbol} 的数据")
                return pd.DataFrame()

            # 处理复权 (如果需要)
            if adjust == "qfq" and not df.empty:
                df = await self._adjust_factor(symbol, df, start_date, end_date)

            # 添加股票代码列
            df['symbol'] = symbol

            # 标准化列名
            df = self._standardize_kline_columns(df)

            logger.info(f"成功获取 {symbol} K线数据，共 {len(df)} 条记录")
            return df

        except Exception as e:
            logger.error(f"获取K线数据失败: {e}")
            raise DataError(f"获取K线数据失败: {e}")

    async def _adjust_factor(self, symbol: str, df: pd.DataFrame, start_date: date, end_date: date) -> pd.DataFrame:
        """获取复权因子并计算前复权价格"""
        try:
            await self._rate_limit_check()

            loop = asyncio.get_event_loop()

            # 获取复权因子
            adj_df = await loop.run_in_executor(
                None,
                lambda: self._ts_api.adj_factor(
                    ts_code=symbol,
                    start_date=start_date.strftime("%Y%m%d"),
                    end_date=end_date.strftime("%Y%m%d")
                )
            )

            if adj_df.empty:
                return df

            # 合并数据并计算复权价格
            df = df.merge(adj_df[['trade_date', 'adj_factor']], on='trade_date', how='left')

            # 前向填充复权因子
            df['adj_factor'] = df['adj_factor'].fillna(method='ffill')
            df['adj_factor'] = df['adj_factor'].fillna(1.0)

            # 计算复权价格
            price_columns = ['open', 'high', 'low', 'close', 'pre_close']
            for col in price_columns:
                if col in df.columns:
                    df[col] = df[col] * df['adj_factor']

            return df.drop('adj_factor', axis=1)

        except Exception as e:
            logger.warning(f"获取复权因子失败，使用原始数据: {e}")
            return df

    async def get_realtime_quote(self, symbols: List[str]) -> pd.DataFrame:
        """获取实时行情 (Tushare 免费版不支持)"""
        logger.warning("Tushare 免费版不支持实时行情数据")
        return pd.DataFrame()

    async def get_stock_list(self, market: str = "A") -> pd.DataFrame:
        """获取股票列表"""
        try:
            if not self._initialized:
                raise DataError("数据源未初始化")

            await self._rate_limit_check()

            loop = asyncio.get_event_loop()

            # 获取股票基本信息
            df = await loop.run_in_executor(
                None,
                lambda: self._ts_api.stock_basic(
                    exchange='',
                    list_status='L',
                    fields='ts_code,symbol,name,area,industry,list_date'
                )
            )

            if df.empty:
                return pd.DataFrame()

            # 重命名列
            df = df.rename(columns={'ts_code': 'symbol', 'name': 'name'})

            logger.info(f"获取到 {len(df)} 只股票的基本信息")
            return df

        except Exception as e:
            logger.error(f"获取股票列表失败: {e}")
            raise DataError(f"获取股票列表失败: {e}")

    async def health_check(self) -> bool:
        """健康检查"""
        try:
            if not self._initialized:
                return False

            await self._rate_limit_check()

            loop = asyncio.get_event_loop()
            # 尝试获取一条股票基本信息
            df = await loop.run_in_executor(
                None,
                lambda: self._ts_api.stock_basic(exchange='', list_status='L', limit=1)
            )
            return not df.empty

        except Exception as e:
            logger.error(f"Tushare 健康检查失败: {e}")
            return False

    def __str__(self) -> str:
        return f"TushareSource(initialized={self._initialized}, rate_limit={self.rate_limit})"


def get_tushare_source(config: Dict[str, Any]) -> TushareSource:
    """获取 Tushare 数据源实例"""
    return TushareSource(config)
```

---

## 步骤 3: pytdx 实时行情接口

### 3.1 创建 pytdx 数据源

创建 `python/pulse_trader/data_sources/pytdx_source.py`:

```python
# python/pulse_trader/data_sources/pytdx_source.py

"""
pytdx 实时行情数据源
"""

import asyncio
from typing import List, Union, Dict, Any, Optional
from datetime import datetime, date, time
import pandas as pd
from pytdx.hq import TdxHq_API
from pytdx.params import TDXParams
from .base import BaseDataSource
from ..exceptions import DataError, NetworkError
from ..utils import get_logger

logger = get_logger(__name__)


class PytdxSource(BaseDataSource):
    """pytdx 实时行情数据源"""

    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.servers = config.get('servers', [
            {'host': '119.147.212.81', 'port': 7709, 'name': '上海期货'},
            {'host': '202.108.253.130', 'port': 7709, 'name': '深圳期货'},
        ])
        self.timeout = config.get('timeout', 5)
        self.retry_count = config.get('retry_count', 3)
        self._api = None
        self._connected_server = None

    async def initialize(self) -> bool:
        """初始化 pytdx 连接"""
        try:
            self._api = TdxHq_API()

            # 尝试连接到可用服务器
            for server in self.servers:
                if await self._connect_to_server(server):
                    self._connected_server = server
                    self._initialized = True
                    logger.info(f"pytdx 连接成功: {server['name']} ({server['host']}:{server['port']})")
                    return True

            logger.error("所有 pytdx 服务器连接失败")
            return False

        except Exception as e:
            logger.error(f"pytdx 初始化失败: {e}")
            return False

    async def _connect_to_server(self, server: Dict[str, Any]) -> bool:
        """连接到指定服务器"""
        try:
            loop = asyncio.get_event_loop()

            # 在线程池中执行同步连接
            connected = await loop.run_in_executor(
                None,
                lambda: self._api.connect(server['host'], server['port'])
            )

            if connected:
                # 测试连接
                test_data = await loop.run_in_executor(
                    None,
                    lambda: self._api.get_security_quotes([(1, '000001')])
                )
                return test_data is not None and len(test_data) > 0

            return False

        except Exception as e:
            logger.warning(f"连接到服务器 {server['host']}:{server['port']} 失败: {e}")
            return False

    async def get_kline_data(
        self,
        symbol: str,
        period: str = "daily",
        start_date: Union[str, date, datetime] = None,
        end_date: Union[str, date, datetime] = None,
        adjust: str = "qfq"
    ) -> pd.DataFrame:
        """获取K线数据"""
        try:
            if not self._initialized:
                raise DataError("数据源未初始化")

            # 验证参数
            symbol = self._validate_symbol(symbol)

            if start_date is None:
                start_date = (datetime.now() - pd.Timedelta(days=365)).date()
            if end_date is None:
                end_date = datetime.now().date()

            start_date, end_date = self._validate_date_range(start_date, end_date)

            # 转换 pytdx 格式
            market_code, stock_code = self._convert_symbol_for_pytdx(symbol)
            period_code = self._convert_period_for_pytdx(period)

            # 获取数据
            loop = asyncio.get_event_loop()

            # pytdx 一次最多获取800条数据
            all_data = []
            current_start = start_date

            while current_start <= end_date:
                try:
                    data = await loop.run_in_executor(
                        None,
                        lambda: self._api.get_k_data(
                            code=stock_code,
                            start_date=current_start.strftime("%Y-%m-%d"),
                            end_date=end_date.strftime("%Y-%m-%d"),
                            market=market_code,
                            ktype=period_code,
                            autype=QfqType.Qfq if adjust == "qfq" else QfqType.None_
                        )
                    )

                    if data and not data.empty:
                        all_data.append(data)

                        # 更新开始日期为最后一条数据的下一天
                        last_date = pd.to_datetime(data.iloc[-1]['date']).date()
                        current_start = last_date + pd.Timedelta(days=1)
                    else:
                        break

                except Exception as e:
                    logger.warning(f"获取 {symbol} 部分数据失败: {e}")
                    break

            if not all_data:
                logger.warning(f"未获取到股票 {symbol} 的数据")
                return pd.DataFrame()

            # 合并所有数据
            df = pd.concat(all_data, ignore_index=True)
            df = df.drop_duplicates(subset=['date']).sort_values('date')

            # 添加股票代码列
            df['symbol'] = symbol

            # 标准化列名
            df = self._standardize_kline_columns(df)

            logger.info(f"成功获取 {symbol} K线数据，共 {len(df)} 条记录")
            return df

        except Exception as e:
            logger.error(f"获取K线数据失败: {e}")
            raise DataError(f"获取K线数据失败: {e}")

    async def get_realtime_quote(self, symbols: List[str]) -> pd.DataFrame:
        """获取实时行情"""
        try:
            if not self._initialized:
                raise DataError("数据源未初始化")

            if not symbols:
                return pd.DataFrame()

            # 转换股票代码格式
            stock_list = []
            for symbol in symbols:
                symbol = self._validate_symbol(symbol)
                market_code, stock_code = self._convert_symbol_for_pytdx(symbol)
                stock_list.append((market_code, stock_code))

            # 分批获取 (每次最多80只股票)
            batch_size = 80
            all_quotes = []

            loop = asyncio.get_event_loop()

            for i in range(0, len(stock_list), batch_size):
                batch = stock_list[i:i + batch_size]

                try:
                    quotes = await loop.run_in_executor(
                        None,
                        lambda: self._api.get_security_quotes(batch)
                    )

                    if quotes:
                        all_quotes.extend(quotes)

                except Exception as e:
                    logger.warning(f"获取第 {i//batch_size + 1} 批实时行情失败: {e}")
                    continue

            if not all_quotes:
                return pd.DataFrame()

            # 转换为 DataFrame
            df = pd.DataFrame(all_quotes)

            # 标准化列名
            column_mapping = {
                'code': 'symbol',
                'price': 'price',
                'vol': 'volume',
                'cur_vol': 'volume',
                'amount': 'amount',
                'open': 'open',
                'high': 'high',
                'low': 'low',
                'pre_close': 'pre_close',
                'last_close': 'pre_close',
            }

            df = df.rename(columns=column_mapping)

            # 添加交易所后缀
            def add_exchange_suffix(code):
                if len(code) == 6:
                    if code.startswith('0') or code.startswith('3'):
                        return f"{code}.SZ"
                    elif code.startswith('6'):
                        return f"{code}.SH"
                    elif code.startswith('8') or code.startswith('4'):
                        return f"{code}.BJ"
                return code

            if 'symbol' in df.columns:
                df['symbol'] = df['symbol'].apply(add_exchange_suffix)

            logger.info(f"成功获取 {len(df)} 只股票的实时行情")
            return df

        except Exception as e:
            logger.error(f"获取实时行情失败: {e}")
            raise NetworkError(f"获取实时行情失败: {e}")

    async def get_stock_list(self, market: str = "A") -> pd.DataFrame:
        """获取股票列表"""
        try:
            if not self._initialized:
                raise DataError("数据源未初始化")

            loop = asyncio.get_event_loop()

            # 获取股票列表
            stocks = await loop.run_in_executor(
                None,
                lambda: self._api.get_security_list(1, 0)  # 1: 深交所, 0: 沪交所
            )

            if not stocks:
                return pd.DataFrame()

            df = pd.DataFrame(stocks)

            # 标准化格式
            df = df[['code', 'name']].copy()
            df.columns = ['symbol', 'name']

            # 添加交易所后缀
            def add_exchange_suffix(code):
                if code.startswith('0') or code.startswith('3'):
                    return f"{code}.SZ"
                elif code.startswith('6'):
                    return f"{code}.SH"
                return code

            df['symbol'] = df['symbol'].apply(add_exchange_suffix)

            logger.info(f"获取到 {len(df)} 只股票的基本信息")
            return df

        except Exception as e:
            logger.error(f"获取股票列表失败: {e}")
            raise DataError(f"获取股票列表失败: {e}")

    async def health_check(self) -> bool:
        """健康检查"""
        try:
            if not self._initialized or not self._api:
                return False

            loop = asyncio.get_event_loop()

            # 尝试获取一只股票的实时行情
            quotes = await loop.run_in_executor(
                None,
                lambda: self._api.get_security_quotes([(1, '000001')])
            )

            return quotes is not None and len(quotes) > 0

        except Exception as e:
            logger.error(f"pytdx 健康检查失败: {e}")
            return False

    def _convert_symbol_for_pytdx(self, symbol: str) -> tuple:
        """转换为 pytdx 格式的股票代码"""
        if '.' not in symbol:
            raise DataError(f"无效的股票代码格式: {symbol}")

        code_part, exchange = symbol.split('.')

        # pytdx 市场代码
        if exchange == 'SZ':
            market = 0  # 深交所
        elif exchange == 'SH':
            market = 1  # 上交所
        elif exchange == 'BJ':
            market = 2  # 北交所
        else:
            raise DataError(f"不支持的交易所: {exchange}")

        return market, code_part

    def _convert_period_for_pytdx(self, period: str) -> int:
        """转换为 pytdx 格式的时间周期"""
        period_mapping = {
            'daily': 9,    # 日K
            '60min': 60,   # 60分钟
            '30min': 30,   # 30分钟
            '15min': 15,   # 15分钟
            '5min': 5,     # 5分钟
            '1min': 1,     # 1分钟
            '1w': 101,     # 周K
            '1m': 102,     # 月K
        }

        return period_mapping.get(period, 9)  # 默认日K

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """清理资源"""
        if self._api:
            try:
                loop = asyncio.get_event_loop()
                await loop.run_in_executor(None, self._api.disconnect)
            except Exception as e:
                logger.warning(f"pytdx 断开连接时出错: {e}")

    def __str__(self) -> str:
        server_info = "未连接"
        if self._connected_server:
            server_info = f"{self._connected_server['name']} ({self._connected_server['host']}:{self._connected_server['port']})"

        return f"PytdxSource(initialized={self._initialized}, server={server_info})"


def get_pytdx_source(config: Dict[str, Any]) -> PytdxSource:
    """获取 pytdx 数据源实例"""
    return PytdxSource(config)
```

---

## 步骤 4: 数据源管理器

### 4.1 创建统一数据源管理器

创建 `python/pulse_trader/data_sources/manager.py`:

```python
# python/pulse_trader/data_sources/manager.py

"""
数据源管理器
"""

import asyncio
from typing import List, Dict, Any, Optional, Union
from datetime import datetime, date
import pandas as pd
from .base import BaseDataSource
from .tushare_source import get_tushare_source
from .akshare_source import get_akshare_source
from .pytdx_source import get_pytdx_source
from ..exceptions import DataError, NetworkError
from ..utils import get_logger, get_config

logger = get_logger(__name__)


class DataSourceManager:
    """数据源管理器"""

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        if config is None:
            app_config = get_config()
            config = app_config.get('data_sources', {})

        self.config = config
        self.sources: Dict[str, BaseDataSource] = {}
        self.primary_source = config.get('primary', 'akshare')
        self.fallback_source = config.get('fallback', 'tushare')
        self.realtime_source = config.get('real_time', 'pytdx')

    async def initialize(self) -> bool:
        """初始化所有数据源"""
        try:
            # 初始化主要数据源
            if self.primary_source and self.primary_source in self.config:
                success = await self._initialize_source(self.primary_source)
                if not success:
                    logger.error(f"主要数据源 {self.primary_source} 初始化失败")

            # 初始化备用数据源
            if self.fallback_source and self.fallback_source in self.config:
                success = await self._initialize_source(self.fallback_source)
                if not success:
                    logger.error(f"备用数据源 {self.fallback_source} 初始化失败")

            # 初始化实时数据源
            if self.realtime_source and self.realtime_source in self.config:
                success = await self._initialize_source(self.realtime_source)
                if not success:
                    logger.error(f"实时数据源 {self.realtime_source} 初始化失败")

            logger.info(f"数据源管理器初始化完成，共加载 {len(self.sources)} 个数据源")
            return len(self.sources) > 0

        except Exception as e:
            logger.error(f"数据源管理器初始化失败: {e}")
            return False

    async def _initialize_source(self, source_name: str) -> bool:
        """初始化单个数据源"""
        try:
            if source_name not in self.config:
                logger.warning(f"未找到数据源配置: {source_name}")
                return False

            source_config = self.config[source_name]

            # 创建数据源实例
            source = self._create_source(source_name, source_config)

            # 初始化数据源
            success = await source.initialize()

            if success:
                self.sources[source_name] = source
                logger.info(f"数据源 {source_name} 初始化成功")
            else:
                logger.error(f"数据源 {source_name} 初始化失败")

            return success

        except Exception as e:
            logger.error(f"初始化数据源 {source_name} 时出错: {e}")
            return False

    def _create_source(self, source_name: str, config: Dict[str, Any]) -> BaseDataSource:
        """创建数据源实例"""
        source_creators = {
            'tushare': get_tushare_source,
            'akshare': get_akshare_source,
            'pytdx': get_pytdx_source,
        }

        if source_name not in source_creators:
            raise DataError(f"不支持的数据源: {source_name}")

        return source_creators[source_name](config)

    async def get_kline_data(
        self,
        symbol: str,
        period: str = "daily",
        start_date: Union[str, date, datetime] = None,
        end_date: Union[str, date, datetime] = None,
        adjust: str = "qfq",
        source_preference: Optional[str] = None
    ) -> pd.DataFrame:
        """
        获取K线数据

        Args:
            symbol: 股票代码
            period: 时间周期
            start_date: 开始日期
            end_date: 结束日期
            adjust: 复权类型
            source_preference: 指定数据源

        Returns:
            K线数据 DataFrame
        """
        # 确定数据源优先级
        sources_to_try = []

        if source_preference and source_preference in self.sources:
            sources_to_try.append(source_preference)

        if self.primary_source in self.sources:
            sources_to_try.append(self.primary_source)

        if self.fallback_source in self.sources and self.fallback_source not in sources_to_try:
            sources_to_try.append(self.fallback_source)

        # 添加其他可用数据源
        for source_name in self.sources:
            if source_name not in sources_to_try:
                sources_to_try.append(source_name)

        last_error = None

        for source_name in sources_to_try:
            try:
                logger.info(f"尝试从数据源 {source_name} 获取 {symbol} K线数据")

                source = self.sources[source_name]
                df = await source.get_kline_data(symbol, period, start_date, end_date, adjust)

                if not df.empty:
                    logger.info(f"成功从 {source_name} 获取 {len(df)} 条 {symbol} K线数据")
                    return df
                else:
                    logger.warning(f"数据源 {source_name} 返回空数据")

            except Exception as e:
                last_error = e
                logger.warning(f"从数据源 {source_name} 获取数据失败: {e}")
                continue

        # 所有数据源都失败
        if last_error:
            raise DataError(f"所有数据源都无法获取数据，最后错误: {last_error}")
        else:
            raise DataError("所有数据源都返回空数据")

    async def get_realtime_quote(self, symbols: List[str]) -> pd.DataFrame:
        """获取实时行情"""
        if not symbols:
            return pd.DataFrame()

        # 优先使用实时数据源
        if self.realtime_source in self.sources:
            try:
                logger.info(f"使用实时数据源 {self.realtime_source} 获取实时行情")
                source = self.sources[self.realtime_source]
                df = await source.get_realtime_quote(symbols)

                if not df.empty:
                    logger.info(f"成功获取 {len(df)} 只股票的实时行情")
                    return df

            except Exception as e:
                logger.warning(f"实时数据源获取失败: {e}")

        # 尝试其他数据源
        for source_name, source in self.sources.items():
            if source_name == self.realtime_source:
                continue

            try:
                df = await source.get_realtime_quote(symbols)
                if not df.empty:
                    logger.info(f"从数据源 {source_name} 获取到实时行情")
                    return df

            except Exception as e:
                logger.warning(f"数据源 {source_name} 获取实时行情失败: {e}")
                continue

        logger.warning("无法获取任何实时行情数据")
        return pd.DataFrame()

    async def get_stock_list(self, market: str = "A") -> pd.DataFrame:
        """获取股票列表"""
        # 按优先级尝试数据源
        source_priority = [self.primary_source, self.fallback_source]

        for source_name in source_priority:
            if source_name not in self.sources:
                continue

            try:
                logger.info(f"从数据源 {source_name} 获取股票列表")
                source = self.sources[source_name]
                df = await source.get_stock_list(market)

                if not df.empty:
                    logger.info(f"成功从 {source_name} 获取 {len(df)} 只股票信息")
                    return df

            except Exception as e:
                logger.warning(f"数据源 {source_name} 获取股票列表失败: {e}")
                continue

        # 尝试其他数据源
        for source_name, source in self.sources.items():
            if source_name in source_priority:
                continue

            try:
                df = await source.get_stock_list(market)
                if not df.empty:
                    logger.info(f"从数据源 {source_name} 获取到股票列表")
                    return df

            except Exception as e:
                logger.warning(f"数据源 {source_name} 获取股票列表失败: {e}")
                continue

        raise DataError("无法从任何数据源获取股票列表")

    async def health_check(self) -> Dict[str, bool]:
        """检查所有数据源的健康状态"""
        health_status = {}

        for source_name, source in self.sources.items():
            try:
                is_healthy = await source.health_check()
                health_status[source_name] = is_healthy

                if is_healthy:
                    logger.info(f"数据源 {source_name} 健康")
                else:
                    logger.warning(f"数据源 {source_name} 不健康")

            except Exception as e:
                health_status[source_name] = False
                logger.error(f"检查数据源 {source_name} 健康状态时出错: {e}")

        return health_status

    def get_available_sources(self) -> List[str]:
        """获取可用的数据源列表"""
        return list(self.sources.keys())

    async def __aenter__(self):
        """异步上下文管理器入口"""
        await self.initialize()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """异步上下文管理器出口"""
        # 清理资源
        for source in self.sources.values():
            try:
                await source.__aexit__(exc_type, exc_val, exc_tb)
            except Exception as e:
                logger.warning(f"清理数据源资源时出错: {e}")


# 全局数据源管理器实例
_manager_instance: Optional[DataSourceManager] = None


async def get_data_manager() -> DataSourceManager:
    """获取全局数据源管理器实例"""
    global _manager_instance

    if _manager_instance is None:
        _manager_instance = DataSourceManager()
        await _manager_instance.initialize()

    return _manager_instance


def reset_data_manager():
    """重置全局数据源管理器"""
    global _manager_instance
    _manager_instance = None
```

---

## 步骤 5: 数据缓存系统

### 5.1 创建数据缓存模块

创建 `python/pulse_trader/cache/__init__.py`:

```python
# python/pulse_trader/cache/__init__.py

"""
数据缓存模块
"""

from .redis_cache import RedisCache
from .file_cache import FileCache
from .memory_cache import MemoryCache
from .manager import CacheManager

__all__ = [
    "RedisCache",
    "FileCache",
    "MemoryCache",
    "CacheManager",
]
```

创建 `python/pulse_trader/cache/file_cache.py`:

```python
# python/pulse_trader/cache/file_cache.py

"""
文件缓存实现
"""

import os
import pickle
import hashlib
from pathlib import Path
from typing import Any, Optional, Dict
from datetime import datetime, timedelta
import pandas as pd
from ..utils import get_logger

logger = get_logger(__name__)


class FileCache:
    """文件缓存实现"""

    def __init__(self, cache_dir: str = "data/cache", default_ttl: int = 3600):
        self.cache_dir = Path(cache_dir)
        self.default_ttl = default_ttl
        self.cache_dir.mkdir(parents=True, exist_ok=True)

    def _get_cache_path(self, key: str) -> Path:
        """获取缓存文件路径"""
        # 使用 MD5 哈希避免文件名过长或包含特殊字符
        hash_key = hashlib.md5(key.encode()).hexdigest()
        return self.cache_dir / f"{hash_key}.cache"

    def _get_metadata_path(self, key: str) -> Path:
        """获取元数据文件路径"""
        hash_key = hashlib.md5(key.encode()).hexdigest()
        return self.cache_dir / f"{hash_key}.meta"

    def _is_expired(self, key: str) -> bool:
        """检查缓存是否过期"""
        meta_path = self._get_metadata_path(key)

        if not meta_path.exists():
            return True

        try:
            with open(meta_path, 'rb') as f:
                metadata = pickle.load(f)

            created_time = metadata.get('created_time')
            ttl = metadata.get('ttl', self.default_ttl)

            if created_time:
                return datetime.now() - created_time > timedelta(seconds=ttl)

            return True

        except Exception as e:
            logger.warning(f"检查缓存过期状态失败: {e}")
            return True

    def set(self, key: str, value: Any, ttl: Optional[int] = None) -> bool:
        """设置缓存"""
        try:
            cache_path = self._get_cache_path(key)
            meta_path = self._get_metadata_path(key)

            # 保存数据
            with open(cache_path, 'wb') as f:
                pickle.dump(value, f)

            # 保存元数据
            metadata = {
                'created_time': datetime.now(),
                'ttl': ttl or self.default_ttl,
                'key': key,
            }

            with open(meta_path, 'wb') as f:
                pickle.dump(metadata, f)

            logger.debug(f"缓存数据成功: {key}")
            return True

        except Exception as e:
            logger.error(f"设置缓存失败: {e}")
            return False

    def get(self, key: str) -> Optional[Any]:
        """获取缓存"""
        try:
            if self._is_expired(key):
                self.delete(key)
                return None

            cache_path = self._get_cache_path(key)

            if not cache_path.exists():
                return None

            with open(cache_path, 'rb') as f:
                value = pickle.load(f)

            logger.debug(f"缓存命中: {key}")
            return value

        except Exception as e:
            logger.error(f"获取缓存失败: {e}")
            return None

    def delete(self, key: str) -> bool:
        """删除缓存"""
        try:
            cache_path = self._get_cache_path(key)
            meta_path = self._get_metadata_path(key)

            deleted = False

            if cache_path.exists():
                cache_path.unlink()
                deleted = True

            if meta_path.exists():
                meta_path.unlink()
                deleted = True

            if deleted:
                logger.debug(f"删除缓存成功: {key}")

            return deleted

        except Exception as e:
            logger.error(f"删除缓存失败: {e}")
            return False

    def clear(self) -> bool:
        """清空所有缓存"""
        try:
            deleted_count = 0

            for file_path in self.cache_dir.glob("*.cache"):
                file_path.unlink()
                deleted_count += 1

            for file_path in self.cache_dir.glob("*.meta"):
                file_path.unlink()
                deleted_count += 1

            logger.info(f"清空缓存完成，删除 {deleted_count} 个文件")
            return True

        except Exception as e:
            logger.error(f"清空缓存失败: {e}")
            return False

    def cleanup_expired(self) -> int:
        """清理过期缓存"""
        try:
            expired_keys = []

            for meta_path in self.cache_dir.glob("*.meta"):
                key = meta_path.stem  # 去掉 .meta 后缀

                if self._is_expired(key):
                    expired_keys.append(key)

            for key in expired_keys:
                self.delete(key)

            logger.info(f"清理过期缓存完成，删除 {len(expired_keys)} 个过期缓存")
            return len(expired_keys)

        except Exception as e:
            logger.error(f"清理过期缓存失败: {e}")
            return 0

    def get_cache_info(self) -> Dict[str, Any]:
        """获取缓存信息"""
        try:
            cache_files = list(self.cache_dir.glob("*.cache"))
            total_size = sum(f.stat().st_size for f in cache_files)

            expired_count = 0
            for meta_path in self.cache_dir.glob("*.meta"):
                key = meta_path.stem
                if self._is_expired(key):
                    expired_count += 1

            return {
                'cache_dir': str(self.cache_dir),
                'total_files': len(cache_files),
                'total_size_bytes': total_size,
                'total_size_mb': round(total_size / 1024 / 1024, 2),
                'expired_files': expired_count,
            }

        except Exception as e:
            logger.error(f"获取缓存信息失败: {e}")
            return {}

    def __contains__(self, key: str) -> bool:
        """检查缓存是否存在且未过期"""
        return not self._is_expired(key)

    def __len__(self) -> int:
        """获取缓存项数量"""
        try:
            count = 0
            for meta_path in self.cache_dir.glob("*.meta"):
                key = meta_path.stem
                if not self._is_expired(key):
                    count += 1
            return count
        except Exception:
            return 0
```

创建 `python/pulse_trader/cache/manager.py`:

```python
# python/pulse_trader/cache/manager.py

"""
缓存管理器
"""

from typing import Any, Optional, Dict, Union
import pandas as pd
from .file_cache import FileCache
from .memory_cache import MemoryCache
from ..utils import get_logger, get_config

logger = get_logger(__name__)


class CacheManager:
    """缓存管理器"""

    def __init__(self, config: Optional[Dict] = None):
        if config is None:
            app_config = get_config()
            config = app_config.get('cache', {})

        self.config = config
        self.cache_type = config.get('type', 'file')

        # 初始化缓存后端
        self._init_cache_backend()

    def _init_cache_backend(self):
        """初始化缓存后端"""
        if self.cache_type == 'file':
            cache_dir = self.config.get('dir', 'data/cache')
            default_ttl = self.config.get('ttl', 3600)
            self.backend = FileCache(cache_dir=cache_dir, default_ttl=default_ttl)
        elif self.cache_type == 'memory':
            max_size = self.config.get('max_size', 1000)
            default_ttl = self.config.get('ttl', 3600)
            self.backend = MemoryCache(max_size=max_size, default_ttl=default_ttl)
        else:
            logger.warning(f"不支持的缓存类型: {self.cache_type}，使用文件缓存")
            self.backend = FileCache()

    def _generate_cache_key(self, prefix: str, **kwargs) -> str:
        """生成缓存键"""
        # 对参数进行排序，确保相同的参数生成相同的键
        sorted_items = sorted(kwargs.items())
        key_parts = [prefix]

        for key, value in sorted_items:
            if value is not None:
                key_parts.append(f"{key}={value}")

        return ":".join(key_parts)

    async def get_kline_data(
        self,
        symbol: str,
        period: str = "daily",
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        adjust: str = "qfq"
    ) -> Optional[pd.DataFrame]:
        """获取缓存的K线数据"""
        cache_key = self._generate_cache_key(
            'kline',
            symbol=symbol,
            period=period,
            start_date=start_date,
            end_date=end_date,
            adjust=adjust
        )

        cached_data = self.backend.get(cache_key)

        if cached_data is not None:
            logger.debug(f"K线数据缓存命中: {symbol}")
            return cached_data
        else:
            logger.debug(f"K线数据缓存未命中: {symbol}")
            return None

    async def set_kline_data(
        self,
        symbol: str,
        data: pd.DataFrame,
        period: str = "daily",
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        adjust: str = "qfq",
        ttl: Optional[int] = None
    ) -> bool:
        """缓存K线数据"""
        if data.empty:
            return False

        cache_key = self._generate_cache_key(
            'kline',
            symbol=symbol,
            period=period,
            start_date=start_date,
            end_date=end_date,
            adjust=adjust
        )

        # 根据数据类型设置不同的TTL
        if ttl is None:
            if period in ['1min', '5min']:
                ttl = 300  # 5分钟
            elif period in ['15min', '30min']:
                ttl = 1800  # 30分钟
            elif period == '60min':
                ttl = 3600  # 1小时
            else:
                ttl = 86400  # 1天

        success = self.backend.set(cache_key, data, ttl=ttl)

        if success:
            logger.debug(f"K线数据缓存成功: {symbol}, {len(data)} 条记录")

        return success

    async def get_stock_list(self, market: str = "A") -> Optional[pd.DataFrame]:
        """获取缓存的股票列表"""
        cache_key = self._generate_cache_key('stock_list', market=market)
        return self.backend.get(cache_key)

    async def set_stock_list(
        self,
        data: pd.DataFrame,
        market: str = "A",
        ttl: Optional[int] = None
    ) -> bool:
        """缓存股票列表"""
        if data.empty:
            return False

        cache_key = self._generate_cache_key('stock_list', market=market)
        ttl = ttl or 86400 * 7  # 默认7天

        success = self.backend.set(cache_key, data, ttl=ttl)

        if success:
            logger.debug(f"股票列表缓存成功: {market}, {len(data)} 条记录")

        return success

    async def get_realtime_quote(self, symbols: list) -> Optional[pd.DataFrame]:
        """获取缓存的实时行情"""
        # 实时行情缓存时间很短
        symbols_str = ",".join(sorted(symbols))
        cache_key = self._generate_cache_key('realtime', symbols=symbols_str)
        return self.backend.get(cache_key)

    async def set_realtime_quote(
        self,
        data: pd.DataFrame,
        symbols: list,
        ttl: Optional[int] = None
    ) -> bool:
        """缓存实时行情"""
        if data.empty:
            return False

        symbols_str = ",".join(sorted(symbols))
        cache_key = self._generate_cache_key('realtime', symbols=symbols_str)
        ttl = ttl or 10  # 默认10秒

        return self.backend.set(cache_key, data, ttl=ttl)

    def delete(self, key: str) -> bool:
        """删除缓存"""
        return self.backend.delete(key)

    def clear(self) -> bool:
        """清空缓存"""
        return self.backend.clear()

    def cleanup_expired(self) -> int:
        """清理过期缓存"""
        return self.backend.cleanup_expired()

    def get_cache_info(self) -> Dict[str, Any]:
        """获取缓存信息"""
        info = self.backend.get_cache_info()
        info['cache_type'] = self.cache_type
        return info

    def __contains__(self, key: str) -> bool:
        """检查缓存是否存在"""
        return key in self.backend

    def __len__(self) -> int:
        """获取缓存项数量"""
        return len(self.backend)


# 全局缓存管理器实例
_cache_manager: Optional[CacheManager] = None


def get_cache_manager() -> CacheManager:
    """获取全局缓存管理器实例"""
    global _cache_manager

    if _cache_manager is None:
        _cache_manager = CacheManager()

    return _cache_manager


def reset_cache_manager():
    """重置全局缓存管理器"""
    global _cache_manager
    _cache_manager = None
```

---

## 步骤 6: 统一数据接口

### 6.1 创建数据服务层

创建 `python/pulse_trader/services/data_service.py`:

```python
# python/pulse_trader/services/data_service.py

"""
数据服务层 - 统一数据接口
"""

import asyncio
from typing import List, Dict, Any, Optional, Union
from datetime import datetime, date
import pandas as pd
from ..data_sources.manager import get_data_manager
from ..cache.manager import get_cache_manager
from ..utils import get_logger
from ..exceptions import DataError, NetworkError

logger = get_logger(__name__)


class DataService:
    """数据服务类 - 提供统一的数据访问接口"""

    def __init__(self):
        self._data_manager = None
        self._cache_manager = get_cache_manager()
        self._initialized = False

    async def initialize(self) -> bool:
        """初始化数据服务"""
        try:
            self._data_manager = await get_data_manager()
            self._initialized = True
            logger.info("数据服务初始化成功")
            return True
        except Exception as e:
            logger.error(f"数据服务初始化失败: {e}")
            return False

    async def get_kline_data(
        self,
        symbol: str,
        period: str = "daily",
        start_date: Union[str, date, datetime] = None,
        end_date: Union[str, date, datetime] = None,
        adjust: str = "qfq",
        use_cache: bool = True,
        force_refresh: bool = False
    ) -> pd.DataFrame:
        """
        获取K线数据

        Args:
            symbol: 股票代码
            period: 时间周期 (daily, weekly, 1min, 5min, 15min, 30min, 60min)
            start_date: 开始日期
            end_date: 结束日期
            adjust: 复权类型 (qfq-前复权, hfq-后复权, none-不复权)
            use_cache: 是否使用缓存
            force_refresh: 是否强制刷新

        Returns:
            K线数据 DataFrame
        """
        if not self._initialized:
            raise DataError("数据服务未初始化")

        # 转换日期格式
        if isinstance(start_date, datetime):
            start_date = start_date.strftime("%Y-%m-%d")
        elif isinstance(start_date, date):
            start_date = start_date.strftime("%Y-%m-%d")

        if isinstance(end_date, datetime):
            end_date = end_date.strftime("%Y-%m-%d")
        elif isinstance(end_date, date):
            end_date = end_date.strftime("%Y-%m-%d")

        # 尝试从缓存获取
        if use_cache and not force_refresh:
            cached_data = await self._cache_manager.get_kline_data(
                symbol, period, start_date, end_date, adjust
            )
            if cached_data is not None and not cached_data.empty:
                logger.info(f"从缓存获取 {symbol} K线数据，共 {len(cached_data)} 条")
                return cached_data

        # 从数据源获取
        try:
            logger.info(f"从数据源获取 {symbol} K线数据")
            df = await self._data_manager.get_kline_data(
                symbol, period, start_date, end_date, adjust
            )

            if df.empty:
                logger.warning(f"未获取到 {symbol} 的K线数据")
                return pd.DataFrame()

            # 缓存数据
            if use_cache:
                await self._cache_manager.set_kline_data(
                    symbol, df, period, start_date, end_date, adjust
                )

            logger.info(f"成功获取 {symbol} K线数据，共 {len(df)} 条")
            return df

        except Exception as e:
            logger.error(f"获取K线数据失败: {e}")
            raise DataError(f"获取K线数据失败: {e}")

    async def get_realtime_quotes(
        self,
        symbols: List[str],
        use_cache: bool = True
    ) -> pd.DataFrame:
        """
        获取实时行情

        Args:
            symbols: 股票代码列表
            use_cache: 是否使用缓存

        Returns:
            实时行情 DataFrame
        """
        if not self._initialized:
            raise DataError("数据服务未初始化")

        if not symbols:
            return pd.DataFrame()

        # 尝试从缓存获取
        if use_cache:
            cached_data = await self._cache_manager.get_realtime_quote(symbols)
            if cached_data is not None and not cached_data.empty:
                logger.info(f"从缓存获取 {len(symbols)} 只股票实时行情")
                return cached_data

        # 从数据源获取
        try:
            logger.info(f"从数据源获取 {len(symbols)} 只股票实时行情")
            df = await self._data_manager.get_realtime_quote(symbols)

            if df.empty:
                logger.warning("未获取到任何实时行情数据")
                return pd.DataFrame()

            # 缓存数据（实时行情缓存时间很短）
            if use_cache:
                await self._cache_manager.set_realtime_quote(df, symbols)

            logger.info(f"成功获取 {len(df)} 只股票实时行情")
            return df

        except Exception as e:
            logger.error(f"获取实时行情失败: {e}")
            # 不抛出异常，返回空DataFrame
            return pd.DataFrame()

    async def get_stock_list(
        self,
        market: str = "A",
        use_cache: bool = True,
        force_refresh: bool = False
    ) -> pd.DataFrame:
        """
        获取股票列表

        Args:
            market: 市场类型
            use_cache: 是否使用缓存
            force_refresh: 是否强制刷新

        Returns:
            股票列表 DataFrame
        """
        if not self._initialized:
            raise DataError("数据服务未初始化")

        # 尝试从缓存获取
        if use_cache and not force_refresh:
            cached_data = await self._cache_manager.get_stock_list(market)
            if cached_data is not None and not cached_data.empty:
                logger.info(f"从缓存获取股票列表，共 {len(cached_data)} 只股票")
                return cached_data

        # 从数据源获取
        try:
            logger.info(f"从数据源获取股票列表")
            df = await self._data_manager.get_stock_list(market)

            if df.empty:
                logger.warning("未获取到股票列表")
                return pd.DataFrame()

            # 缓存数据
            if use_cache:
                await self._cache_manager.set_stock_list(df, market)

            logger.info(f"成功获取股票列表，共 {len(df)} 只股票")
            return df

        except Exception as e:
            logger.error(f"获取股票列表失败: {e}")
            raise DataError(f"获取股票列表失败: {e}")

    async def batch_get_kline_data(
        self,
        symbols: List[str],
        period: str = "daily",
        start_date: Union[str, date, datetime] = None,
        end_date: Union[str, date, datetime] = None,
        adjust: str = "qfq",
        max_concurrent: int = 10
    ) -> Dict[str, pd.DataFrame]:
        """
        批量获取K线数据

        Args:
            symbols: 股票代码列表
            period: 时间周期
            start_date: 开始日期
            end_date: 结束日期
            adjust: 复权类型
            max_concurrent: 最大并发数

        Returns:
            股票代码到K线数据的映射
        """
        if not symbols:
            return {}

        logger.info(f"开始批量获取 {len(symbols)} 只股票的K线数据")

        # 创建信号量限制并发数
        semaphore = asyncio.Semaphore(max_concurrent)

        async def get_single_kline(symbol: str) -> tuple[str, pd.DataFrame]:
            async with semaphore:
                try:
                    df = await self.get_kline_data(
                        symbol, period, start_date, end_date, adjust
                    )
                    return symbol, df
                except Exception as e:
                    logger.warning(f"获取 {symbol} K线数据失败: {e}")
                    return symbol, pd.DataFrame()

        # 并发获取所有数据
        tasks = [get_single_kline(symbol) for symbol in symbols]
        results = await asyncio.gather(*tasks)

        # 整理结果
        data_dict = {}
        success_count = 0

        for symbol, df in results:
            if not df.empty:
                data_dict[symbol] = df
                success_count += 1
            else:
                logger.warning(f"股票 {symbol} 无数据")

        logger.info(f"批量获取完成，成功 {success_count}/{len(symbols)} 只股票")
        return data_dict

    async def health_check(self) -> Dict[str, Any]:
        """健康检查"""
        if not self._initialized:
            return {
                'data_service': False,
                'data_sources': {},
                'cache': {},
            }

        # 检查数据源健康状态
        data_sources_health = await self._data_manager.health_check()

        # 检查缓存状态
        cache_info = self._cache_manager.get_cache_info()

        return {
            'data_service': True,
            'data_sources': data_sources_health,
            'cache': cache_info,
            'available_sources': self._data_manager.get_available_sources(),
        }

    def clear_cache(self) -> bool:
        """清空缓存"""
        return self._cache_manager.clear()

    def cleanup_cache(self) -> int:
        """清理过期缓存"""
        return self._cache_manager.cleanup_expired()


# 全局数据服务实例
_data_service: Optional[DataService] = None


async def get_data_service() -> DataService:
    """获取全局数据服务实例"""
    global _data_service

    if _data_service is None:
        _data_service = DataService()
        await _data_service.initialize()

    return _data_service


def reset_data_service():
    """重置全局数据服务实例"""
    global _data_service
    _data_service = None
```

### 6.2 更新主模块

更新 `python/pulse_trader/__init__.py`:

```python
# python/pulse_trader/__init__.py

"""
PulseTrader - A股量化交易系统

高性能Rust+Python混合架构的量化交易平台
"""

__version__ = "0.3.0"
__author__ = "Your Name"
__email__ = "your.email@example.com"

# 核心模块
from .engine import get_engine
from .services.data_service import get_data_service, DataService

# 数据源
from .data_sources.manager import get_data_manager, DataSourceManager

# 异常
from .exceptions import (
    PulseTraderError,
    DataError,
    NetworkError,
    CalculationError,
    ConfigError,
    ValidationError,
)

# 工具
from .utils import get_logger, setup_logging, load_config, get_config

__all__ = [
    # 版本信息
    "__version__",
    "__author__",
    "__email__",

    # 核心功能
    "get_engine",
    "get_data_service",
    "DataService",

    # 数据源
    "get_data_manager",
    "DataSourceManager",

    # 异常
    "PulseTraderError",
    "DataError",
    "NetworkError",
    "CalculationError",
    "ConfigError",
    "ValidationError",

    # 工具
    "get_logger",
    "setup_logging",
    "load_config",
    "get_config",
]
```

---

## 步骤 7: 创建测试和示例

### 7.1 创建数据层测试

创建 `python/tests/test_data_service.py`:

```python
# python/tests/test_data_service.py

"""
数据服务测试
"""

import pytest
import asyncio
from datetime import datetime, timedelta
import pandas as pd
from pulse_trader.services.data_service import DataService
from pulse_trader.exceptions import DataError


class TestDataService:
    """数据服务测试类"""

    @pytest.fixture
    async def data_service(self):
        """数据服务测试夹具"""
        service = DataService()
        await service.initialize()
        yield service

    @pytest.mark.asyncio
    async def test_get_kline_data(self, data_service):
        """测试获取K线数据"""
        df = await data_service.get_kline_data(
            "000001.SZ",
            start_date="2023-01-01",
            end_date="2023-01-10"
        )

        assert isinstance(df, pd.DataFrame)
        if not df.empty:
            required_columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume']
            for col in required_columns:
                assert col in df.columns

    @pytest.mark.asyncio
    async def test_get_realtime_quotes(self, data_service):
        """测试获取实时行情"""
        symbols = ["000001.SZ", "600000.SH"]
        df = await data_service.get_realtime_quotes(symbols)

        assert isinstance(df, pd.DataFrame)
        # 注意：实时行情可能因为网络问题获取失败，所以不强制要求非空

    @pytest.mark.asyncio
    async def test_get_stock_list(self, data_service):
        """测试获取股票列表"""
        df = await data_service.get_stock_list()

        assert isinstance(df, pd.DataFrame)
        if not df.empty:
            assert 'symbol' in df.columns
            assert 'name' in df.columns

    @pytest.mark.asyncio
    async def test_batch_get_kline_data(self, data_service):
        """测试批量获取K线数据"""
        symbols = ["000001.SZ", "600000.SH"]

        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=30)

        data_dict = await data_service.batch_get_kline_data(
            symbols,
            start_date=start_date,
            end_date=end_date,
            max_concurrent=2
        )

        assert isinstance(data_dict, dict)
        for symbol in symbols:
            if symbol in data_dict:
                assert isinstance(data_dict[symbol], pd.DataFrame)

    @pytest.mark.asyncio
    async def test_health_check(self, data_service):
        """测试健康检查"""
        health_info = await data_service.health_check()

        assert isinstance(health_info, dict)
        assert 'data_service' in health_info
        assert 'data_sources' in health_info
        assert 'cache' in health_info

    @pytest.mark.asyncio
    async def test_cache_functionality(self, data_service):
        """测试缓存功能"""
        symbol = "000001.SZ"
        start_date = "2023-01-01"
        end_date = "2023-01-05"

        # 清除可能的缓存
        data_service.clear_cache()

        # 第一次获取（应该从数据源获取）
        df1 = await data_service.get_kline_data(
            symbol, start_date=start_date, end_date=end_date
        )

        # 第二次获取（应该从缓存获取）
        df2 = await data_service.get_kline_data(
            symbol, start_date=start_date, end_date=end_date
        )

        # 验证两次获取的数据相同
        if not df1.empty and not df2.empty:
            pd.testing.assert_frame_equal(df1, df2)


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
```

### 7.2 创建使用示例

创建 `examples/data_service_demo.py`:

```python
#!/usr/bin/env python3
"""
数据服务使用示例
"""

import asyncio
import sys
import os
from datetime import datetime, timedelta

# 添加项目路径
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'python'))

from pulse_trader import (
    get_data_service,
    setup_logging,
    get_logger,
    DataError
)


async def demo_basic_usage():
    """基本使用演示"""
    print("=== 数据服务基本使用演示 ===\n")

    # 设置日志
    setup_logging(level="INFO")
    logger = get_logger(__name__)

    try:
        # 获取数据服务
        logger.info("初始化数据服务...")
        data_service = await get_data_service()

        # 1. 获取单只股票的K线数据
        print("1. 获取平安银行(000001.SZ)最近30天K线数据")
        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=30)

        df = await data_service.get_kline_data(
            symbol="000001.SZ",
            start_date=start_date,
            end_date=end_date
        )

        if not df.empty:
            print(f"   获取到 {len(df)} 条K线数据")
            print(f"   数据列: {list(df.columns)}")
            print(f"   最新数据:\n{df.tail(3)}")
        else:
            print("   未获取到数据")

        print()

        # 2. 获取实时行情
        print("2. 获取实时行情")
        symbols = ["000001.SZ", "600000.SH", "600036.SH"]
        quotes = await data_service.get_realtime_quotes(symbols)

        if not quotes.empty:
            print(f"   获取到 {len(quotes)} 只股票的实时行情")
            print(f"   行情数据:\n{quotes[['symbol', 'price', 'change_pct']]}")
        else:
            print("   未获取到实时行情数据")

        print()

        # 3. 批量获取K线数据
        print("3. 批量获取多只股票K线数据")
        batch_symbols = ["000001.SZ", "600000.SH", "600036.SH"]

        batch_data = await data_service.batch_get_kline_data(
            symbols=batch_symbols,
            start_date=start_date,
            end_date=end_date,
            max_concurrent=3
        )

        print(f"   成功获取 {len(batch_data)} 只股票的数据")
        for symbol, data in batch_data.items():
            print(f"   {symbol}: {len(data)} 条记录")

        print()

        # 4. 健康检查
        print("4. 数据服务健康检查")
        health_info = await data_service.health_check()

        print("   数据源状态:")
        for source, status in health_info['data_sources'].items():
            status_text = "正常" if status else "异常"
            print(f"   {source}: {status_text}")

        print(f"   缓存信息: {health_info['cache']}")

        print("\n=== 演示完成 ===")

    except DataError as e:
        logger.error(f"数据错误: {e}")
    except Exception as e:
        logger.error(f"未知错误: {e}")


async def demo_cache_usage():
    """缓存使用演示"""
    print("\n=== 缓存功能演示 ===\n")

    logger = get_logger(__name__)

    try:
        data_service = await get_data_service()

        symbol = "000001.SZ"
        start_date = "2023-01-01"
        end_date = "2023-01-10"

        # 清除缓存
        print("1. 清除缓存")
        cleared = data_service.clear_cache()
        print(f"   清除结果: {'成功' if cleared else '失败'}")

        # 第一次获取（从数据源）
        print("\n2. 第一次获取数据（从数据源）")
        import time
        start_time = time.time()
        df1 = await data_service.get_kline_data(symbol, start_date=start_date, end_date=end_date)
        first_duration = time.time() - start_time
        print(f"   耗时: {first_duration:.3f} 秒")

        # 第二次获取（从缓存）
        print("\n3. 第二次获取数据（从缓存）")
        start_time = time.time()
        df2 = await data_service.get_kline_data(symbol, start_date=start_date, end_date=end_date)
        second_duration = time.time() - start_time
        print(f"   耗时: {second_duration:.3f} 秒")

        # 性能比较
        if first_duration > 0 and second_duration > 0:
            speedup = first_duration / second_duration
            print(f"   缓存加速比: {speedup:.1f}x")

        # 清理过期缓存
        print("\n4. 清理过期缓存")
        cleaned_count = data_service.cleanup_cache()
        print(f"   清理了 {cleaned_count} 个过期缓存项")

        print("\n=== 缓存演示完成 ===")

    except Exception as e:
        logger.error(f"缓存演示失败: {e}")


async def main():
    """主函数"""
    print("PulseTrader 数据服务演示程序")
    print("=" * 50)

    try:
        await demo_basic_usage()
        await demo_cache_usage()
    except KeyboardInterrupt:
        print("\n程序被用户中断")
    except Exception as e:
        print(f"\n程序执行出错: {e}")


if __name__ == "__main__":
    asyncio.run(main())
```

---

## ✅ 完成检查清单

### 数据源实现
- [ ] Tushare 数据源已实现
- [ ] akshare 数据源已集成
- [ ] pytdx 实时行情接口已实现
- [ ] 数据源管理器已完成

### 缓存系统
- [ ] 文件缓存已实现
- [ ] 内存缓存已实现
- [ ] 缓存管理器已完成
- [ ] 缓存策略已配置

### 数据服务层
- [ ] 统一数据接口已实现
- [ ] 批量数据获取功能已完成
- [ ] 错误处理和重试机制已实现
- [ ] 性能优化已完成

### 测试和示例
- [ ] 单元测试已编写
- [ ] 集成测试已通过
- [ ] 使用示例已创建
- [ ] 性能测试已完成

---

## 🚨 常见问题解决

### 问题 1: Tushare Token 配置错误
**解决方案**:
```bash
# 检查配置文件
cat config/.env

# 确保TOKEN格式正确
# TUSHARE_TOKEN=你的实际token
```

### 问题 2: 数据源连接超时
**解决方案**:
```python
# 在配置文件中增加超时时间
data_sources:
  tushare:
    timeout: 30
  akshare:
    timeout: 30
  pytdx:
    timeout: 10
    retry_count: 3
```

### 问题 3: 缓存权限问题
**解决方案**:
```bash
# 确保缓存目录有写权限
mkdir -p data/cache
chmod 755 data/cache
```

---

## 📝 开发记录

**完成时间**: ___________
**实际耗时**: ___________

### 实现的功能
1.
2.
3.

### 遇到的问题
1.
2.
3.

### 性能优化
1.
2.
3.

### 数据质量验证结果
1.
2.
3.

---

## 🎯 下一步

第三阶段完成后，您可以：

1. **提交代码**:
   ```bash
   git add .
   git commit -m "feat: 完成第三阶段数据层开发

   - 实现Tushare、akshare、pytdx数据源
   - 创建统一数据源管理器
   - 实现文件和内存缓存系统
   - 构建数据服务层
   - 添加数据质量验证
   - 完成测试和使用示例"
   ```

2. **开始第四阶段**:
   ```bash
   git checkout -b feature/fourth-phase
   ```

3. **阅读下一阶段文档**: [14-第四阶段-策略回测.md](./14-第四阶段-策略回测.md)

**恭喜完成第三阶段！** 🎉 您已经建立了完整的数据层架构，为策略开发和回测提供了强大的数据支持。