# 2.1 é€šè¾¾ä¿¡æ•°æ®æ ¼å¼è§£æ

## ğŸ“– æœ¬èŠ‚æ¦‚è¿°

æœ¬èŠ‚å°†è¯¦ç»†ä»‹ç»é€šè¾¾ä¿¡æ•°æ®æ–‡ä»¶çš„äºŒè¿›åˆ¶æ ¼å¼ï¼Œå®ç°Rustè¯­è¨€çš„é«˜æ€§èƒ½è§£æå™¨ã€‚é€šè¾¾ä¿¡dayæ–‡ä»¶é‡‡ç”¨ç´§å‡‘çš„äºŒè¿›åˆ¶æ ¼å¼å­˜å‚¨ï¼Œæ¯åªè‚¡ç¥¨çš„å†å²æ•°æ®æŒ‰æ—¥æœŸé¡ºåºæ’åˆ—ï¼ŒåŒ…å«å®Œæ•´çš„OHLCVä¿¡æ¯å’Œå„ç§æŠ€æœ¯æŒ‡æ ‡ã€‚

## ğŸ¯ å­¦ä¹ ç›®æ ‡

å®Œæˆæœ¬èŠ‚å­¦ä¹ åï¼Œæ‚¨å°†èƒ½å¤Ÿï¼š
- âœ… ç†è§£é€šè¾¾ä¿¡dayæ–‡ä»¶çš„äºŒè¿›åˆ¶æ•°æ®ç»“æ„
- âœ… å®ç°é«˜æ•ˆçš„äºŒè¿›åˆ¶æ•°æ®è§£æå™¨
- âœ… å¤„ç†ä¸åŒå¸‚åœºçš„æ•°æ®æ ¼å¼å·®å¼‚
- âœ… å®ç°æ•°æ®éªŒè¯å’Œé”™è¯¯æ¢å¤æœºåˆ¶
- âœ… ä¼˜åŒ–å†…å­˜ä½¿ç”¨å’Œè§£ææ€§èƒ½

## â±ï¸ é¢„è®¡æ—¶é—´ï¼š50-60åˆ†é’Ÿ

---

## ğŸ“Š é€šè¾¾ä¿¡æ•°æ®æ ¼å¼åˆ†æ

### 1. é€šè¾¾ä¿¡dayæ–‡ä»¶ç»“æ„

é€šè¾¾ä¿¡çš„æ—¥çº¿æ•°æ®æ–‡ä»¶ï¼ˆ.dayï¼‰é‡‡ç”¨äºŒè¿›åˆ¶æ ¼å¼å­˜å‚¨ï¼Œæ–‡ä»¶ç»“æ„å¦‚ä¸‹ï¼š

```rust
// æ–‡ä»¶å¤´ä¿¡æ¯ (é€šå¸¸32å­—èŠ‚)
struct TDXDayHeader {
    // ä¿ç•™å­—æ®µï¼Œé€šå¸¸ä¸º0æˆ–ç‰¹å®šæ ‡è¯†
    reserved: [u8; 32],
}

// æ¯æ¡æ—¥çº¿è®°å½• (32å­—èŠ‚)
struct TDXDayRecord {
    date: u32,           // äº¤æ˜“æ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
    open: u32,           // å¼€ç›˜ä»·ï¼Œåˆ†ä¸ºå•ä½
    high: u32,           // æœ€é«˜ä»·ï¼Œåˆ†ä¸ºå•ä½
    low: u32,            // æœ€ä½ä»·ï¼Œåˆ†ä¸ºå•ä½
    close: u32,          // æ”¶ç›˜ä»·ï¼Œåˆ†ä¸ºå•ä½
    amount: f32,         // æˆäº¤é¢ï¼Œå…ƒä¸ºå•ä½
    volume: u32,         // æˆäº¤é‡ï¼Œè‚¡ä¸ºå•ä½
    reserved: u32,       // ä¿ç•™å­—æ®µ
}
```

### 2. æ•°æ®æ–‡ä»¶å‘½åè§„åˆ™

é€šè¾¾ä¿¡æ•°æ®æ–‡ä»¶æŒ‰ä»¥ä¸‹è§„åˆ™å‘½åï¼š

- **æ²ªå¸‚Aè‚¡**: `sh600000.day`
- **æ·±å¸‚Aè‚¡**: `sz000001.day`
- **æŒ‡æ•°æ–‡ä»¶**: `sz399001.day`
- **åˆ›ä¸šæ¿**: `sz300001.day`

### 3. æ•°æ®æ–‡ä»¶ç›®å½•ç»“æ„

```
data/tdx/vipdoc/
â”œâ”€â”€ sh/               # æ²ªå¸‚æ•°æ®
â”‚   â”œâ”€â”€ day/          # æ—¥çº¿æ•°æ®
â”‚   â”œâ”€â”€ min1/         # 1åˆ†é’Ÿçº¿
â”‚   â”œâ”€â”€ min5/         # 5åˆ†é’Ÿçº¿
â”‚   â””â”€â”€ tdxhy.cfg     # é…ç½®æ–‡ä»¶
â””â”€â”€ sz/               # æ·±å¸‚æ•°æ®
    â”œâ”€â”€ day/          # æ—¥çº¿æ•°æ®
    â”œâ”€â”€ min1/         # 1åˆ†é’Ÿçº¿
    â”œâ”€â”€ min5/         # 5åˆ†é’Ÿçº¿
    â””â”€â”€ tdxhy.cfg     # é…ç½®æ–‡ä»¶
```

---

## ğŸ› ï¸ Rustè§£æå™¨å®ç°

### 1. åˆ›å»ºRusté¡¹ç›®ç»“æ„

é¦–å…ˆåˆ›å»ºRusté¡¹ç›®çš„é…ç½®æ–‡ä»¶ï¼š

**rust/Cargo.toml**
```toml
[package]
name = "pulse-trader-rust"
version = "0.1.0"
edition = "2021"
authors = ["Your Name <your.email@example.com>"]
description = "é«˜æ€§èƒ½é‡åŒ–äº¤æ˜“æ•°æ®å¤„ç†æ¨¡å—"
license = "MIT"

[lib]
name = "pulse_trader_rust"
crate-type = ["cdylib", "rlib"]

[dependencies]
# Pythonç»‘å®š
pyo3 = { version = "0.20", features = ["extension-module"] }

# å¼‚æ­¥è¿è¡Œæ—¶
tokio = { version = "1.0", features = ["full"] }

# æ•°æ®åº“
clickhouse-rs = "0.1.0"

# åºåˆ—åŒ–
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# é”™è¯¯å¤„ç†
anyhow = "1.0"
thiserror = "1.0"

# æ—¥å¿—
log = "0.4"
env_logger = "0.10"

# å¹¶å‘
rayon = "1.8"

# æ—¶é—´å¤„ç†
chrono = { version = "0.4", features = ["serde"] }

# æ•°å€¼å¤„ç†
num-traits = "0.2"

# å‹ç¼©
flate2 = "1.0"
zip = "0.6"

# æ–‡ä»¶ç³»ç»Ÿ
walkdir = "2.0"

# é…ç½®
config = "0.14"

[dev-dependencies]
criterion = "0.5"
tempfile = "3.0"

[[bench]]
name = "tdx_parser_bench"
harness = false

[features]
default = ["python-bindings"]
python-bindings = ["pyo3"]

[profile.release]
lto = true
codegen-units = 1
panic = "abort"
```

### 2. å®ç°æ ¸å¿ƒæ•°æ®ç»“æ„

**rust/src/parsers/mod.rs**
```rust
//! æ•°æ®è§£æå™¨æ¨¡å—

pub mod tdx_day;
pub mod utils;

pub use tdx_day::*;
pub use utils::*;
```

**rust/src/parsers/tdx_day.rs**
```rust
//! é€šè¾¾ä¿¡æ—¥çº¿æ•°æ®è§£æå™¨

use anyhow::{Context, Result};
use chrono::{NaiveDate, Utc};
use serde::{Deserialize, Serialize};
use std::fs::File;
use std::io::{BufRead, BufReader, Read};
use std::path::{Path, PathBuf};
use walkdir::WalkDir;

/// é€šè¾¾ä¿¡æ—¥çº¿è®°å½•ç»“æ„
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TDXDayRecord {
    /// äº¤æ˜“æ—¥æœŸ
    pub date: NaiveDate,
    /// è‚¡ç¥¨ä»£ç 
    pub symbol: String,
    /// å¼€ç›˜ä»·ï¼ˆå…ƒï¼‰
    pub open: f64,
    /// æœ€é«˜ä»·ï¼ˆå…ƒï¼‰
    pub high: f64,
    /// æœ€ä½ä»·ï¼ˆå…ƒï¼‰
    pub low: f64,
    /// æ”¶ç›˜ä»·ï¼ˆå…ƒï¼‰
    pub close: f64,
    /// æˆäº¤é‡ï¼ˆè‚¡ï¼‰
    pub volume: u64,
    /// æˆäº¤é¢ï¼ˆå…ƒï¼‰
    pub amount: f64,
    /// å¸‚åœºï¼ˆSH/SZï¼‰
    pub market: String,
}

/// äºŒè¿›åˆ¶æ ¼å¼çš„æ—¥çº¿è®°å½•ï¼ˆå†…å­˜ä¸­ï¼‰
#[repr(C, packed)]
#[derive(Debug)]
struct BinaryDayRecord {
    date: u32,
    open: u32,
    high: u32,
    low: u32,
    close: u32,
    amount: f32,
    volume: u32,
    reserved: u32,
}

impl BinaryDayRecord {
    /// å­—èŠ‚å¤§å°
    const SIZE: usize = std::mem::size_of::<BinaryDayRecord>();
}

/// é€šè¾¾ä¿¡è§£æå™¨
#[derive(Debug)]
pub struct TDXDayParser {
    /// æ•°æ®æ ¹ç›®å½•
    data_root: PathBuf,
}

impl TDXDayParser {
    /// åˆ›å»ºæ–°çš„è§£æå™¨
    pub fn new<P: AsRef<Path>>(data_root: P) -> Self {
        Self {
            data_root: data_root.as_ref().to_path_buf(),
        }
    }

    /// è§£æå•ä¸ªdayæ–‡ä»¶
    pub fn parse_file<P: AsRef<Path>>(&self, file_path: P) -> Result<Vec<TDXDayRecord>> {
        let file_path = file_path.as_ref();

        // ä»æ–‡ä»¶è·¯å¾„æå–è‚¡ç¥¨ä»£ç å’Œå¸‚åœº
        let (symbol, market) = self.extract_symbol_market(file_path)?;

        // è¯»å–æ–‡ä»¶å†…å®¹
        let mut file = File::open(file_path)
            .with_context(|| format!("æ— æ³•æ‰“å¼€æ–‡ä»¶: {}", file_path.display()))?;

        let mut buffer = Vec::new();
        file.read_to_end(&mut buffer)
            .with_context(|| format!("æ— æ³•è¯»å–æ–‡ä»¶: {}", file_path.display()))?;

        // è§£æäºŒè¿›åˆ¶æ•°æ®
        self.parse_binary_data(&buffer, &symbol, &market)
    }

    /// è§£æäºŒè¿›åˆ¶æ•°æ®
    fn parse_binary_data(
        &self,
        buffer: &[u8],
        symbol: &str,
        market: &str,
    ) -> Result<Vec<TDXDayRecord>> {
        if buffer.len() % BinaryDayRecord::SIZE != 0 {
            return Err(anyhow::anyhow!(
                "æ–‡ä»¶å¤§å°ä¸æ­£ç¡®ï¼ŒæœŸæœ›{}çš„å€æ•°ï¼Œå®é™…{}å­—èŠ‚",
                BinaryDayRecord::SIZE,
                buffer.len()
            ));
        }

        let record_count = buffer.len() / BinaryDayRecord::SIZE;
        let mut records = Vec::with_capacity(record_count);

        for i in 0..record_count {
            let offset = i * BinaryDayRecord::SIZE;
            let record_slice = &buffer[offset..offset + BinaryDayRecord::SIZE];

            // å®‰å…¨åœ°è½¬æ¢å­—èŠ‚æ•°ç»„åˆ°ç»“æ„ä½“
            let binary_record: BinaryDayRecord = unsafe {
                std::ptr::read_unaligned(record_slice.as_ptr() as *const _)
            };

            // è½¬æ¢ä¸ºé«˜çº§æ•°æ®ç»“æ„
            let record = self.convert_binary_record(&binary_record, symbol, market)?;
            records.push(record);
        }

        // æŒ‰æ—¥æœŸæ’åºï¼ˆé€šè¾¾ä¿¡æ•°æ®é€šå¸¸æ˜¯æ­£åºçš„ï¼Œä½†ç¡®ä¿ä¸€è‡´æ€§ï¼‰
        records.sort_by(|a, b| a.date.cmp(&b.date));

        Ok(records)
    }

    /// è½¬æ¢äºŒè¿›åˆ¶è®°å½•åˆ°ç»“æ„åŒ–æ•°æ®
    fn convert_binary_record(
        &self,
        binary: &BinaryDayRecord,
        symbol: &str,
        market: &str,
    ) -> Result<TDXDayRecord> {
        // éªŒè¯æ—¥æœŸæœ‰æ•ˆæ€§
        let date_str = binary.date.to_string();
        if date_str.len() != 8 {
            return Err(anyhow::anyhow!("æ— æ•ˆçš„æ—¥æœŸæ ¼å¼: {}", date_str));
        }

        let year = date_str[0..4].parse::<i32>()
            .with_context(|| format!("æ— æ•ˆçš„å¹´ä»½: {}", &date_str[0..4]))?;
        let month = date_str[4..6].parse::<u32>()
            .with_context(|| format!("æ— æ•ˆçš„æœˆä»½: {}", &date_str[4..6]))?;
        let day = date_str[6..8].parse::<u32>()
            .with_context(|| format!("æ— æ•ˆçš„æ—¥æœŸ: {}", &date_str[6..8]))?;

        let date = NaiveDate::from_ymd_opt(year, month, day)
            .ok_or_else(|| anyhow::anyhow!("æ— æ•ˆçš„æ—¥æœŸ: {}", date_str))?;

        // ä»·æ ¼è½¬æ¢ï¼ˆåˆ†ä¸ºå•ä½è½¬æ¢ä¸ºå…ƒï¼‰
        let open = binary.open as f64 / 100.0;
        let high = binary.high as f64 / 100.0;
        let low = binary.low as f64 / 100.0;
        let close = binary.close as f64 / 100.0;

        // éªŒè¯ä»·æ ¼åˆç†æ€§
        self.validate_prices(open, high, low, close)?;

        Ok(TDXDayRecord {
            date,
            symbol: symbol.to_string(),
            open,
            high,
            low,
            close,
            volume: binary.volume as u64,
            amount: binary.amount as f64,
            market: market.to_string(),
        })
    }

    /// éªŒè¯ä»·æ ¼æ•°æ®åˆç†æ€§
    fn validate_prices(&self, open: f64, high: f64, low: f64, close: f64) -> Result<()> {
        // æ£€æŸ¥ä»·æ ¼æ˜¯å¦ä¸ºæ­£æ•°
        if open <= 0.0 || high <= 0.0 || low <= 0.0 || close <= 0.0 {
            return Err(anyhow::anyhow!("ä»·æ ¼å¿…é¡»ä¸ºæ­£æ•°"));
        }

        // æ£€æŸ¥é«˜ä½ä»·å…³ç³»
        if high < low {
            return Err(anyhow::anyhow!("æœ€é«˜ä»·ä¸èƒ½ä½äºæœ€ä½ä»·"));
        }

        // æ£€æŸ¥å¼€æ”¶ç›˜ä»·æ˜¯å¦åœ¨é«˜ä½ä»·èŒƒå›´å†…
        if open > high || open < low || close > high || close < low {
            return Err(anyhow::anyhow!("å¼€æ”¶ç›˜ä»·è¶…å‡ºé«˜ä½ä»·èŒƒå›´"));
        }

        // æ£€æŸ¥ä»·æ ¼æ˜¯å¦åˆç†ï¼ˆ1åˆ†-10000å…ƒï¼‰
        if open < 0.01 || high > 10000.0 || low < 0.01 || close > 10000.0 {
            return Err(anyhow::anyhow!("ä»·æ ¼è¶…å‡ºåˆç†èŒƒå›´"));
        }

        Ok(())
    }

    /// ä»æ–‡ä»¶è·¯å¾„æå–è‚¡ç¥¨ä»£ç å’Œå¸‚åœº
    fn extract_symbol_market(&self, file_path: &Path) -> Result<(String, String)> {
        let file_name = file_path.file_stem()
            .and_then(|s| s.to_str())
            .ok_or_else(|| anyhow::anyhow!("æ— æ•ˆçš„æ–‡ä»¶å"))?;

        if file_name.len() != 6 {
            return Err(anyhow::anyhow!("è‚¡ç¥¨ä»£ç é•¿åº¦é”™è¯¯"));
        }

        // æ ¹æ®ç›®å½•åˆ¤æ–­å¸‚åœº
        let path_str = file_path.to_string_lossy().to_lowercase();
        let market = if path_str.contains("/sh/") || path_str.contains("\\sh\\") {
            "SH"
        } else if path_str.contains("/sz/") || path_str.contains("\\sz\\") {
            "SZ"
        } else {
            return Err(anyhow::anyhow!("æ— æ³•ç¡®å®šå¸‚åœºï¼Œè·¯å¾„ä¸­ç¼ºå°‘å¸‚åœºä¿¡æ¯"));
        };

        Ok((file_name.to_string(), market.to_string()))
    }

    /// è§£æç›®å½•ä¸‹çš„æ‰€æœ‰dayæ–‡ä»¶
    pub fn parse_directory<P: AsRef<Path>>(&self, dir_path: P) -> Result<Vec<TDXDayRecord>> {
        let dir_path = dir_path.as_ref();
        let mut all_records = Vec::new();

        if !dir_path.exists() {
            return Err(anyhow::anyhow!("ç›®å½•ä¸å­˜åœ¨: {}", dir_path.display()));
        }

        // éå†ç›®å½•ä¸‹çš„æ‰€æœ‰.dayæ–‡ä»¶
        for entry in WalkDir::new(dir_path)
            .into_iter()
            .filter_map(|e| e.ok())
        {
            let path = entry.path();

            if path.extension().and_then(|s| s.to_str()) == Some("day") {
                match self.parse_file(path) {
                    Ok(mut records) => {
                        info!("è§£ææ–‡ä»¶æˆåŠŸ: {}, {}æ¡è®°å½•", path.display(), records.len());
                        all_records.append(&mut records);
                    }
                    Err(e) => {
                        warn!("è§£ææ–‡ä»¶å¤±è´¥ {}: {}", path.display(), e);
                        // ç»§ç»­å¤„ç†å…¶ä»–æ–‡ä»¶ï¼Œä¸ä¸­æ–­æ•´ä¸ªè¿‡ç¨‹
                    }
                }
            }
        }

        // æŒ‰æ—¥æœŸå’Œè‚¡ç¥¨ä»£ç æ’åº
        all_records.sort_by(|a, b| {
            a.date.cmp(&b.date)
                .then(a.symbol.cmp(&b.symbol))
                .then(a.market.cmp(&b.market))
        });

        Ok(all_records)
    }

    /// è·å–æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨
    pub fn get_stock_list(&self) -> Result<Vec<(String, String)>> {
        let mut stocks = Vec::new();
        let markets = ["sh", "sz"];

        for market in &markets {
            let market_dir = self.data_root.join("vipdoc").join(market).join("day");

            if market_dir.exists() {
                for entry in std::fs::read_dir(&market_dir)? {
                    let entry = entry?;
                    let path = entry.path();

                    if path.extension().and_then(|s| s.to_str()) == Some("day") {
                        if let Some(file_stem) = path.file_stem().and_then(|s| s.to_str()) {
                            if file_stem.len() == 6 && file_stem.chars().all(|c| c.is_ascii_digit()) {
                                let market_str = market.to_uppercase();
                                stocks.push((file_stem.to_string(), market_str.to_string()));
                            }
                        }
                    }
                }
            }
        }

        // æ’åºè‚¡ç¥¨åˆ—è¡¨
        stocks.sort();
        Ok(stocks)
    }

    /// è·å–æŒ‡å®šæ—¥æœŸçš„æ•°æ®
    pub fn get_data_by_date(&self, target_date: NaiveDate) -> Result<Vec<TDXDayRecord>> {
        let all_records = self.parse_directory(
            self.data_root.join("vipdoc").join("sh").join("day")
        )?;

        let sz_records = self.parse_directory(
            self.data_root.join("vipdoc").join("sz").join("day")
        )?;

        let mut combined_records = all_records;
        combined_records.extend(sz_records);

        // è¿‡æ»¤æŒ‡å®šæ—¥æœŸçš„æ•°æ®
        Ok(combined_records
            .into_iter()
            .filter(|record| record.date == target_date)
            .collect())
    }

    /// è·å–æŒ‡å®šè‚¡ç¥¨çš„å†å²æ•°æ®
    pub fn get_data_by_symbol(&self, symbol: &str, market: &str) -> Result<Vec<TDXDayRecord>> {
        let file_path = self.data_root
            .join("vipdoc")
            .join(market.to_lowercase())
            .join("day")
            .join(format!("{}.day", symbol));

        self.parse_file(file_path)
    }

    /// è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯
    pub fn get_statistics(&self) -> Result<TDXStatistics> {
        let stocks = self.get_stock_list()?;
        let total_stocks = stocks.len();
        let mut total_records = 0;
        let mut earliest_date = None;
        let mut latest_date = None;
        let mut sh_count = 0;
        let mut sz_count = 0;

        for (symbol, market) in &stocks {
            match self.get_data_by_symbol(symbol, market) {
                Ok(records) => {
                    total_records += records.len();

                    if let Some(first_record) = records.first() {
                        match &earliest_date {
                            None => earliest_date = Some(first_record.date),
                            Some(current) => {
                                if first_record.date < *current {
                                    earliest_date = Some(first_record.date);
                                }
                            }
                        }

                        match &latest_date {
                            None => latest_date = Some(first_record.date),
                            Some(current) => {
                                if first_record.date > *current {
                                    latest_date = Some(first_record.date);
                                }
                            }
                        }
                    }

                    match market {
                        "SH" => sh_count += 1,
                        "SZ" => sz_count += 1,
                        _ => {}
                    }
                }
                Err(_) => {
                    // å¿½ç•¥æ— æ³•è¯»å–çš„è‚¡ç¥¨æ•°æ®
                }
            }
        }

        Ok(TDXStatistics {
            total_stocks,
            total_records,
            sh_count,
            sz_count,
            earliest_date,
            latest_date,
            data_size_bytes: self.calculate_data_size()?,
        })
    }

    /// è®¡ç®—æ•°æ®æ–‡ä»¶æ€»å¤§å°
    fn calculate_data_size(&self) -> Result<u64> {
        let mut total_size = 0u64;

        for entry in WalkDir::new(&self.data_root)
            .into_iter()
            .filter_map(|e| e.ok())
        {
            let path = entry.path();
            if path.is_file() {
                if let Some(metadata) = path.metadata().ok() {
                    total_size += metadata.len();
                }
            }
        }

        Ok(total_size)
    }
}

/// æ•°æ®ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Serialize, Deserialize)]
pub struct TDXStatistics {
    /// æ€»è‚¡ç¥¨æ•°
    pub total_stocks: usize,
    /// æ€»è®°å½•æ•°
    pub total_records: usize,
    /// æ²ªå¸‚è‚¡ç¥¨æ•°
    pub sh_count: usize,
    /// æ·±å¸‚è‚¡ç¥¨æ•°
    pub sz_count: usize,
    /// æœ€æ—©æ—¥æœŸ
    pub earliest_date: Option<NaiveDate>,
    /// æœ€æ–°æ—¥æœŸ
    pub latest_date: Option<NaiveDate>,
    /// æ•°æ®æ–‡ä»¶æ€»å¤§å°ï¼ˆå­—èŠ‚ï¼‰
    pub data_size_bytes: u64,
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::path::PathBuf;
    use tempfile::TempDir;

    #[test]
    fn test_tdx_parser_creation() {
        let temp_dir = TempDir::new().unwrap();
        let parser = TDXDayParser::new(temp_dir.path());

        assert_eq!(parser.data_root, temp_dir.path());
    }

    #[test]
    fn test_symbol_extraction() {
        let temp_dir = TempDir::new().unwrap();
        let parser = TDXDayParser::new(temp_dir.path());

        // åˆ›å»ºæµ‹è¯•è·¯å¾„
        let sh_path = temp_dir.path().join("vipdoc").join("sh").join("day").join("600000.day");
        let (symbol, market) = parser.extract_symbol_market(&sh_path).unwrap();

        assert_eq!(symbol, "600000");
        assert_eq!(market, "SH");
    }

    #[test]
    fn test_binary_record_size() {
        assert_eq!(BinaryDayRecord::SIZE, 32);
    }
}
```

### 3. åˆ›å»ºè§£æå·¥å…·æ¨¡å—

**rust/src/parsers/utils.rs**
```rust
//! è§£æå™¨å·¥å…·æ¨¡å—

use anyhow::Result;
use std::fs::{self, File};
use std::io::{BufReader, Read};
use std::path::{Path, PathBuf};
use flate2::read::GzDecoder;
use zip::ZipArchive;

/// æ–‡ä»¶å¤„ç†å·¥å…·
pub struct FileUtils;

impl FileUtils {
    /// æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¯è¯»
    pub fn check_file_readable<P: AsRef<Path>>(file_path: P) -> Result<()> {
        let path = file_path.as_ref();

        if !path.exists() {
            return Err(anyhow::anyhow!("æ–‡ä»¶ä¸å­˜åœ¨: {}", path.display()));
        }

        if !path.is_file() {
            return Err(anyhow::anyhow!("è·¯å¾„ä¸æ˜¯æ–‡ä»¶: {}", path.display()));
        }

        // å°è¯•æ‰“å¼€æ–‡ä»¶éªŒè¯å¯è¯»æ€§
        File::open(path)
            .with_context(|| format!("æ–‡ä»¶ä¸å¯è¯»: {}", path.display()))?;

        Ok(())
    }

    /// åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    pub fn ensure_dir_exists<P: AsRef<Path>>(dir_path: P) -> Result<()> {
        let path = dir_path.as_ref();

        if !path.exists() {
            fs::create_dir_all(path)
                .with_context(|| format!("æ— æ³•åˆ›å»ºç›®å½•: {}", path.display()))?;
        }

        Ok(())
    }

    /// è·å–æ–‡ä»¶å¤§å°
    pub fn get_file_size<P: AsRef<Path>>(file_path: P) -> Result<u64> {
        let path = file_path.as_ref();

        let metadata = path.metadata()
            .with_context(|| format!("æ— æ³•è·å–æ–‡ä»¶å…ƒæ•°æ®: {}", path.display()))?;

        Ok(metadata.len())
    }

    /// å¤åˆ¶æ–‡ä»¶
    pub fn copy_file<P: AsRef<Path>, Q: AsRef<Path>>(from: P, to: Q) -> Result<u64> {
        let from_path = from.as_ref();
        let to_path = to.as_ref();

        // ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
        if let Some(parent) = to_path.parent() {
            Self::ensure_dir_exists(parent)?;
        }

        let bytes_copied = fs::copy(from_path, to_path)
            .with_context(|| {
                format!("æ— æ³•å¤åˆ¶æ–‡ä»¶ä» {} åˆ° {}",
                    from_path.display(), to_path.display())
            })?;

        Ok(bytes_copied)
    }

    /// ç§»åŠ¨æ–‡ä»¶
    pub fn move_file<P: AsRef<Path>, Q: AsRef<Path>>(from: P, to: Q) -> Result<()> {
        let from_path = from.as_ref();
        let to_path = to.as_ref();

        // ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
        if let Some(parent) = to_path.parent() {
            Self::ensure_dir_exists(parent)?;
        }

        fs::rename(from_path, to_path)
            .with_context(|| {
                format!("æ— æ³•ç§»åŠ¨æ–‡ä»¶ä» {} åˆ° {}",
                    from_path.display(), to_path.display())
            })?;

        Ok(())
    }
}

/// å‹ç¼©æ–‡ä»¶å¤„ç†å·¥å…·
pub struct CompressionUtils;

impl CompressionUtils {
    /// è§£å‹gzipæ–‡ä»¶
    pub fn extract_gzip<P: AsRef<Path>, Q: AsRef<Path>>(
        gzip_path: P,
        output_path: Q
    ) -> Result<()> {
        let gzip_file = File::open(gzip_path.as_ref())
            .with_context(|| format!("æ— æ³•æ‰“å¼€gzipæ–‡ä»¶: {}", gzip_path.as_ref().display()))?;

        let decoder = GzDecoder::new(gzip_file);
        let mut output_file = File::create(output_path.as_ref())
            .with_context(|| format!("æ— æ³•åˆ›å»ºè¾“å‡ºæ–‡ä»¶: {}", output_path.as_ref().display()))?;

        std::io::copy(decoder, &mut output_file)
            .with_context(|| "è§£å‹gzipæ–‡ä»¶å¤±è´¥")?;

        Ok(())
    }

    /// è§£å‹zipæ–‡ä»¶åˆ°æŒ‡å®šç›®å½•
    pub fn extract_zip<P: AsRef<Path>>(zip_path: P, extract_dir: P) -> Result<()> {
        let zip_file = File::open(zip_path.as_ref())
            .with_context(|| format!("æ— æ³•æ‰“å¼€zipæ–‡ä»¶: {}", zip_path.as_ref().display()))?;

        let mut archive = ZipArchive::new(zip_file)
            .with_context(|| "æ— æ³•è¯»å–zipå½’æ¡£")?;

        for i in 0..archive.len() {
            let mut file = archive.by_index(i)
                .with_context(|| format!("æ— æ³•è·å–zipæ–‡ä»¶ç´¢å¼•: {}", i))?;

            let output_path = extract_dir.as_ref().join(file.name());

            if file.name().ends_with('/') {
                // åˆ›å»ºç›®å½•
                FileUtils::ensure_dir_exists(&output_path)?;
            } else {
                // åˆ›å»ºæ–‡ä»¶çš„çˆ¶ç›®å½•
                if let Some(parent) = output_path.parent() {
                    FileUtils::ensure_dir_exists(parent)?;
                }

                // æå–æ–‡ä»¶
                let mut output_file = File::create(&output_path)
                    .with_context(|| format!("æ— æ³•åˆ›å»ºè¾“å‡ºæ–‡ä»¶: {}", output_path.display()))?;

                std::io::copy(&mut file, &mut output_file)
                    .with_context(|| format!("æå–æ–‡ä»¶å¤±è´¥: {}", file.name()))?;
            }
        }

        Ok(())
    }

    /// å‹ç¼©ç›®å½•ä¸ºzipæ–‡ä»¶
    pub fn compress_to_zip<P: AsRef<Path>, Q: AsRef<Path>>(
        source_dir: P,
        zip_path: Q
    ) -> Result<()> {
        let source_path = source_dir.as_ref();
        let zip_file = File::create(zip_path.as_ref())
            .with_context(|| format!("æ— æ³•åˆ›å»ºzipæ–‡ä»¶: {}", zip_path.as_ref().display()))?;

        let mut zip = ZipWriter::new(zip_file);
        let options = FileOptions::default()
            .compression_method(zip::CompressionMethod::Stored);

        // æ·»åŠ ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
        for entry in walkdir::WalkDir::new(source_path)
            .into_iter()
            .filter_map(|e| e.ok())
        {
            let path = entry.path();
            let name = path.strip_prefix(source_path)
                .with_context(|| "è·¯å¾„å‰ç¼€å¤„ç†å¤±è´¥")?;

            if path.is_file() {
                zip.start_file(name.to_string_lossy(), options)?;
                let mut file = File::open(path)?;
                std::io::copy(&mut file, &mut zip)?;
            } else if path != source_path {
                zip.add_directory(name.to_string_lossy(), options)?;
            }
        }

        zip.finish()?;
        Ok(())
    }
}

/// æ•°æ®éªŒè¯å·¥å…·
pub struct ValidationUtils;

impl ValidationUtils {
    /// éªŒè¯è‚¡ç¥¨ä»£ç æ ¼å¼
    pub fn validate_symbol(symbol: &str) -> Result<()> {
        if symbol.len() != 6 {
            return Err(anyhow::anyhow!("è‚¡ç¥¨ä»£ç é•¿åº¦é”™è¯¯ï¼ŒæœŸæœ›6ä½: {}", symbol));
        }

        if !symbol.chars().all(|c| c.is_ascii_digit()) {
            return Err(anyhow::anyhow!("è‚¡ç¥¨ä»£ç å¿…é¡»ä¸ºæ•°å­—: {}", symbol));
        }

        Ok(())
    }

    /// éªŒè¯å¸‚åœºä»£ç 
    pub fn validate_market(market: &str) -> Result<()> {
        match market.to_uppercase().as_str() {
            "SH" | "SZ" => Ok(()),
            _ => Err(anyhow::anyhow!("æ— æ•ˆçš„å¸‚åœºä»£ç ï¼ŒæœŸæœ›SHæˆ–SZ: {}", market)),
        }
    }

    /// éªŒè¯æ—¥æœŸæ ¼å¼
    pub fn validate_date(date_str: &str) -> Result<chrono::NaiveDate> {
        if date_str.len() != 8 {
            return Err(anyhow::anyhow!("æ—¥æœŸæ ¼å¼é”™è¯¯ï¼ŒæœŸæœ›YYYYMMDD: {}", date_str));
        }

        let year = date_str[0..4].parse::<i32>()
            .with_context(|| "æ— æ•ˆçš„å¹´ä»½")?;
        let month = date_str[4..6].parse::<u32>()
            .with_context(|| "æ— æ•ˆçš„æœˆä»½")?;
        let day = date_str[6..8].parse::<u32>()
            .with_context(|| "æ— æ•ˆçš„æ—¥æœŸ")?;

        chrono::NaiveDate::from_ymd_opt(year, month, day)
            .ok_or_else(|| anyhow::anyhow!("æ— æ•ˆçš„æ—¥æœŸ: {}", date_str))
    }

    /// éªŒè¯ä»·æ ¼æ•°æ®
    pub fn validate_price_data(
        open: f64,
        high: f64,
        low: f64,
        close: f64
    ) -> Result<()> {
        // æ£€æŸ¥ä»·æ ¼ä¸ºæ­£æ•°
        if open <= 0.0 || high <= 0.0 || low <= 0.0 || close <= 0.0 {
            return Err(anyhow::anyhow!("ä»·æ ¼å¿…é¡»ä¸ºæ­£æ•°"));
        }

        // æ£€æŸ¥é«˜ä½ä»·å…³ç³»
        if high < low {
            return Err(anyhow::anyhow!("æœ€é«˜ä»·ä¸èƒ½ä½äºæœ€ä½ä»·"));
        }

        // æ£€æŸ¥å¼€æ”¶ç›˜ä»·åœ¨é«˜ä½ä»·èŒƒå›´å†…
        if open > high || open < low || close > high || close < low {
            return Err(anyhow::anyhow!("å¼€æ”¶ç›˜ä»·è¶…å‡ºé«˜ä½ä»·èŒƒå›´"));
        }

        // æ£€æŸ¥ä»·æ ¼åˆç†æ€§
        if open < 0.01 || high > 10000.0 || low < 0.01 || close > 10000.0 {
            return Err(anyhow::anyhow!("ä»·æ ¼è¶…å‡ºåˆç†èŒƒå›´"));
        }

        Ok(())
    }

    /// éªŒè¯æˆäº¤é‡æ•°æ®
    pub fn validate_volume(volume: u64) -> Result<()> {
        if volume > 10_u64.pow(12) {  // 1ä¸‡äº¿è‚¡ä¸Šé™
            return Err(anyhow::anyhow!("æˆäº¤é‡è¶…å‡ºåˆç†èŒƒå›´: {}", volume));
        }

        Ok(())
    }

    /// éªŒè¯æˆäº¤é¢æ•°æ®
    pub fn validate_amount(amount: f64) -> Result<()> {
        if amount < 0.0 || amount > 10_f64.pow(15) {  // 1åƒä¸‡äº¿ä¸Šé™
            return Err(anyhow::anyhow!("æˆäº¤é¢è¶…å‡ºåˆç†èŒƒå›´: {}", amount));
        }

        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::TempDir;

    #[test]
    fn test_symbol_validation() {
        // æœ‰æ•ˆè‚¡ç¥¨ä»£ç 
        assert!(ValidationUtils::validate_symbol("000001").is_ok());
        assert!(ValidationUtils::validate_symbol("600000").is_ok());
        assert!(ValidationUtils::validate_symbol("300001").is_ok());

        // æ— æ•ˆè‚¡ç¥¨ä»£ç 
        assert!(ValidationUtils::validate_symbol("00001").is_err());  // é•¿åº¦é”™è¯¯
        assert!(ValidationUtils::validate_symbol("AAAAAA").is_err());  // éæ•°å­—
        assert!(ValidationUtils::validate_symbol("0000000").is_err()); // é•¿åº¦é”™è¯¯
    }

    #[test]
    fn test_market_validation() {
        // æœ‰æ•ˆå¸‚åœºä»£ç 
        assert!(ValidationUtils::validate_market("SH").is_ok());
        assert!(ValidationUtils::validate_market("SZ").is_ok());
        assert!(ValidationUtils::validate_market("sh").is_ok());
        assert!(ValidationUtils::validate_market("sz").is_ok());

        // æ— æ•ˆå¸‚åœºä»£ç 
        assert!(ValidationUtils::validate_market("BJ").is_err());
        assert!(ValidationUtils::validate_market("HK").is_err());
    }

    #[test]
    fn test_date_validation() {
        // æœ‰æ•ˆæ—¥æœŸ
        assert!(ValidationUtils::validate_date("20240101").is_ok());
        assert!(ValidationUtils::validate_date("20231231").is_ok());

        // æ— æ•ˆæ—¥æœŸ
        assert!(ValidationUtils::validate_date("2024011").is_err());   // é•¿åº¦é”™è¯¯
        assert!(ValidationUtils::validate_date("20241301").is_err()); // æœˆä»½æ— æ•ˆ
        assert!(ValidationUtils::validate_date("20240132").is_err()); // æ—¥æœŸæ— æ•ˆ
    }

    #[test]
    fn test_price_validation() {
        // æœ‰æ•ˆä»·æ ¼æ•°æ®
        assert!(ValidationUtils::validate_price_data(10.0, 12.0, 8.0, 11.0).is_ok());

        // æ— æ•ˆä»·æ ¼æ•°æ®
        assert!(ValidationUtils::validate_price_data(-1.0, 12.0, 8.0, 11.0).is_err()); // è´Ÿä»·æ ¼
        assert!(ValidationUtils::validate_price_data(10.0, 8.0, 12.0, 11.0).is_err()); // é«˜ä½ä»·å…³ç³»é”™è¯¯
        assert!(ValidationUtils::validate_price_data(13.0, 12.0, 8.0, 11.0).is_err()); // å¼€ç›˜ä»·è¶…å‡ºèŒƒå›´
    }

    #[test]
    fn test_file_ensure_dir() {
        let temp_dir = TempDir::new().unwrap();
        let test_dir = temp_dir.path().join("test").join("nested");

        // ç¡®ä¿ç›®å½•åˆ›å»ºæˆåŠŸ
        assert!(FileUtils::ensure_dir_exists(&test_dir).is_ok());
        assert!(test_dir.exists());
        assert!(test_dir.is_dir());
    }
}
```

### 4. åˆ›å»ºæ•°æ®ä¸‹è½½å·¥å…·

**scripts/data/download_tdx_data.py**
```python
#!/usr/bin/env python3
"""
é€šè¾¾ä¿¡æ•°æ®ä¸‹è½½å·¥å…·
"""

import os
import sys
import requests
import zipfile
from pathlib import Path
from typing import Optional
import logging
import argparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent.parent))

logger = logging.getLogger(__name__)

class TDXDataDownloader:
    """é€šè¾¾ä¿¡æ•°æ®ä¸‹è½½å™¨"""

    def __init__(self, data_dir: Path = None):
        """
        åˆå§‹åŒ–ä¸‹è½½å™¨

        Args:
            data_dir: æ•°æ®ç›®å½•è·¯å¾„
        """
        if data_dir is None:
            self.data_dir = Path("data/tdx")
        else:
            self.data_dir = data_dir

        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        self.data_dir.mkdir(parents=True, exist_ok=True)

        # é€šè¾¾ä¿¡æ•°æ®ä¸‹è½½URL
        self.base_url = "https://data.tdx.com.cn/vipdoc/"
        self.data_files = {
            "sh_day": "sh/day.zip",
            "sz_day": "sz/day.zip"
        }

    def download_file(self, url: str, local_path: Path, timeout: int = 300) -> bool:
        """
        ä¸‹è½½æ–‡ä»¶

        Args:
            url: ä¸‹è½½URL
            local_path: æœ¬åœ°ä¿å­˜è·¯å¾„
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            ä¸‹è½½æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info(f"å¼€å§‹ä¸‹è½½: {url}")

            # åˆ›å»ºè¯·æ±‚å¤´
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }

            # å‘é€HTTPè¯·æ±‚
            response = requests.get(url, headers=headers, stream=True, timeout=timeout)
            response.raise_for_status()

            # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
            local_path.parent.mkdir(parents=True, exist_ok=True)

            # å†™å…¥æ–‡ä»¶
            total_size = int(response.headers.get('content-length', 0))
            downloaded_size = 0

            with open(local_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded_size += len(chunk)

                        # æ˜¾ç¤ºä¸‹è½½è¿›åº¦
                        if total_size > 0:
                            progress = (downloaded_size / total_size) * 100
                            print(f"\rä¸‹è½½è¿›åº¦: {progress:.1f}%", end='', flush=True)

            print()  # æ¢è¡Œ

            logger.info(f"ä¸‹è½½å®Œæˆ: {local_path}")
            return True

        except Exception as e:
            logger.error(f"ä¸‹è½½å¤±è´¥ {url}: {e}")
            return False

    def extract_zip(self, zip_path: Path, extract_dir: Path) -> bool:
        """
        è§£å‹ZIPæ–‡ä»¶

        Args:
            zip_path: ZIPæ–‡ä»¶è·¯å¾„
            extract_dir: è§£å‹ç›®å½•

        Returns:
            è§£å‹æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info(f"å¼€å§‹è§£å‹: {zip_path}")

            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(extract_dir)

            logger.info(f"è§£å‹å®Œæˆ: {extract_dir}")
            return True

        except Exception as e:
            logger.error(f"è§£å‹å¤±è´¥ {zip_path}: {e}")
            return False

    def download_all_data(self, force: bool = False) -> bool:
        """
        ä¸‹è½½æ‰€æœ‰é€šè¾¾ä¿¡æ•°æ®

        Args:
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½

        Returns:
            ä¸‹è½½æ˜¯å¦æˆåŠŸ
        """
        success = True

        for name, relative_path in self.data_files.items():
            url = self.base_url + relative_path

            # æ„é€ æœ¬åœ°è·¯å¾„
            zip_filename = f"{name}.zip"
            zip_path = self.data_dir / zip_filename

            # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸‹è½½
            if not force and zip_path.exists():
                logger.info(f"æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {zip_filename}")
            else:
                # ä¸‹è½½ZIPæ–‡ä»¶
                if not self.download_file(url, zip_path):
                    success = False
                    continue

                # è§£å‹æ–‡ä»¶
                extract_dir = self.data_dir / "vipdoc"
                if not self.extract_zip(zip_path, extract_dir):
                    success = False

                # åˆ é™¤ZIPæ–‡ä»¶ä»¥èŠ‚çœç©ºé—´
                try:
                    zip_path.unlink()
                    logger.info(f"åˆ é™¤ZIPæ–‡ä»¶: {zip_filename}")
                except Exception as e:
                    logger.warning(f"åˆ é™¤ZIPæ–‡ä»¶å¤±è´¥: {e}")

        return success

    def check_data_integrity(self) -> dict:
        """
        æ£€æŸ¥æ•°æ®å®Œæ•´æ€§

        Returns:
            å®Œæ•´æ€§æ£€æŸ¥ç»“æœ
        """
        result = {
            "vipdoc_sh_exists": False,
            "vipdoc_sz_exists": False,
            "sh_files_count": 0,
            "sz_files_count": 0,
            "total_size_mb": 0
        }

        try:
            vipdoc_dir = self.data_dir / "vipdoc"

            if vipdoc_dir.exists():
                # æ£€æŸ¥æ²ªå¸‚æ•°æ®
                sh_dir = vipdoc_dir / "sh" / "day"
                if sh_dir.exists():
                    result["vipdoc_sh_exists"] = True
                    for file_path in sh_dir.glob("*.day"):
                        result["sh_files_count"] += 1
                        if file_path.is_file():
                            result["total_size_mb"] += file_path.stat().st_size / (1024 * 1024)

                # æ£€æŸ¥æ·±å¸‚æ•°æ®
                sz_dir = vipdoc_dir / "sz" / "day"
                if sz_dir.exists():
                    result["vipdoc_sz_exists"] = True
                    for file_path in sz_dir.glob("*.day"):
                        result["sz_files_count"] += 1
                        if file_path.is_file():
                            result["total_size_mb"] += file_path.stat().st_size / (1024 * 1024)

        except Exception as e:
            logger.error(f"æ£€æŸ¥æ•°æ®å®Œæ•´æ€§å¤±è´¥: {e}")

        return result


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="é€šè¾¾ä¿¡æ•°æ®ä¸‹è½½å·¥å…·")
    parser.add_argument("--data-dir", type=Path, help="æ•°æ®ç›®å½•è·¯å¾„")
    parser.add_argument("--force", action="store_true", help="å¼ºåˆ¶é‡æ–°ä¸‹è½½")
    parser.add_argument("--check-only", action="store_true", help="ä»…æ£€æŸ¥æ•°æ®å®Œæ•´æ€§")

    args = parser.parse_args()

    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )

    # åˆ›å»ºä¸‹è½½å™¨
    downloader = TDXDataDownloader(args.data_dir)

    if args.check_only:
        # ä»…æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        print("=== æ•°æ®å®Œæ•´æ€§æ£€æŸ¥ ===")
        result = downloader.check_data_integrity()

        print(f"æ²ªå¸‚æ•°æ®ç›®å½•: {'å­˜åœ¨' if result['vipdoc_sh_exists'] else 'ä¸å­˜åœ¨'}")
        print(f"æ·±å¸‚æ•°æ®ç›®å½•: {'å­˜åœ¨' if result['vipdoc_sz_exists'] else 'ä¸å­˜åœ¨'}")
        print(f"æ²ªå¸‚æ–‡ä»¶æ•°é‡: {result['sh_files_count']}")
        print(f"æ·±å¸‚æ–‡ä»¶æ•°é‡: {result['sz_files_count']}")
        print(f"æ€»æ•°æ®å¤§å°: {result['total_size_mb']:.2f} MB")

        if result['sh_files_count'] > 0 and result['sz_files_count'] > 0:
            print("\nâœ… æ•°æ®å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡")
        else:
            print("\nâŒ æ•°æ®ä¸å®Œæ•´ï¼Œå»ºè®®é‡æ–°ä¸‹è½½")

    else:
        # ä¸‹è½½æ•°æ®
        print("=== é€šè¾¾ä¿¡æ•°æ®ä¸‹è½½ ===")
        print(f"æ•°æ®ç›®å½•: {downloader.data_dir}")

        success = downloader.download_all_data(force=args.force)

        if success:
            print("\nâœ… æ•°æ®ä¸‹è½½æˆåŠŸ")

            # æ£€æŸ¥ä¸‹è½½ç»“æœ
            result = downloader.check_data_integrity()
            print(f"\nä¸‹è½½ç»Ÿè®¡:")
            print(f"  æ²ªå¸‚æ–‡ä»¶: {result['sh_files_count']} ä¸ª")
            print(f"  æ·±å¸‚æ–‡ä»¶: {result['sz_files_count']} ä¸ª")
            print(f"  æ€»å¤§å°: {result['total_size_mb']:.2f} MB")
        else:
            print("\nâŒ æ•°æ®ä¸‹è½½å¤±è´¥")
            sys.exit(1)


if __name__ == "__main__":
    main()
```

---

## ğŸ§ª æµ‹è¯•Rustè§£æå™¨

### 1. åˆ›å»ºæµ‹è¯•è„šæœ¬

**rust/tests/tdx_parser_tests.rs**
```rust
use anyhow::Result;
use pulse_trader_rust::parsers::{TDXDayParser, TDXStatistics};
use std::path::PathBuf;
use tempfile::TempDir;
use std::fs;

#[test]
fn test_parser_creation() {
    let temp_dir = TempDir::new().unwrap();
    let parser = TDXDayParser::new(temp_dir.path());

    assert_eq!(parser.data_root, temp_dir.path());
}

#[test]
fn test_symbol_extraction() {
    let temp_dir = TempDir::new().unwrap();
    let parser = TDXDayParser::new(temp_dir.path());

    // åˆ›å»ºæµ‹è¯•ç›®å½•ç»“æ„
    let sh_dir = temp_dir.path().join("vipdoc").join("sh").join("day");
    fs::create_dir_all(&sh_dir).unwrap();

    let test_file = sh_dir.join("600000.day");

    let (symbol, market) = parser.extract_symbol_market(&test_file).unwrap();

    assert_eq!(symbol, "600000");
    assert_eq!(market, "SH");
}

#[test]
fn test_data_validation() {
    use pulse_trader_rust::parsers::ValidationUtils;

    // æµ‹è¯•è‚¡ç¥¨ä»£ç éªŒè¯
    assert!(ValidationUtils::validate_symbol("000001").is_ok());
    assert!(ValidationUtils::validate_symbol("AAAAAA").is_err());

    // æµ‹è¯•å¸‚åœºéªŒè¯
    assert!(ValidationUtils::validate_market("SH").is_ok());
    assert!(ValidationUtils::validate_market("BJ").is_err());

    // æµ‹è¯•ä»·æ ¼éªŒè¯
    assert!(ValidationUtils::validate_price_data(10.0, 12.0, 8.0, 11.0).is_ok());
    assert!(ValidationUtils::validate_price_data(-1.0, 12.0, 8.0, 11.0).is_err());
}

#[test]
fn test_statistics_calculation() {
    let temp_dir = TempDir::new().unwrap();
    let parser = TDXDayParser::new(temp_dir.path());

    // åˆ›å»ºæµ‹è¯•æ•°æ®ç›®å½•
    let sh_dir = temp_dir.path().join("vipdoc").join("sh").join("day");
    let sz_dir = temp_dir.path().join("vipdoc").join("sz").join("day");
    fs::create_dir_all(&sh_dir).unwrap();
    fs::create_dir_all(&sz_dir).unwrap();

    // åˆ›å»ºç©ºçš„ç»Ÿè®¡ä¿¡æ¯
    let stats = parser.get_statistics().unwrap();

    assert_eq!(stats.total_stocks, 0);
    assert_eq!(stats.sh_count, 0);
    assert_eq!(stats.sz_count, 0);
}
```

### 2. åˆ›å»ºåŸºå‡†æµ‹è¯•

**rust/benches/tdx_parser_bench.rs**
```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion};
use pulse_trader_rust::parsers::TDXDayParser;
use std::fs;
use tempfile::TempDir;

fn create_test_data(temp_dir: &TempDir) -> Vec<u8> {
    // åˆ›å»ºæµ‹è¯•äºŒè¿›åˆ¶æ•°æ®
    let test_records = vec![
        // æ—¥æœŸ, å¼€ç›˜ä»·, æœ€é«˜ä»·, æœ€ä½ä»·, æ”¶ç›˜ä»·, æˆäº¤é¢, æˆäº¤é‡, ä¿ç•™
        20240101u32, 1000u32, 1050u32, 980u32, 1020u32, 1040000.0f32, 1000000u32, 0u32,
        20240102u32, 1020u32, 1080u32, 1000u32, 1060u32, 1080000.0f32, 1200000u32, 0u32,
        20240103u32, 1060u32, 1120u32, 1040u32, 1100u32, 1120000.0f32, 1400000u32, 0u32,
    ];

    // è½¬æ¢ä¸ºå­—èŠ‚æ•°ç»„
    unsafe {
        std::slice::from_raw_parts(
            test_records.as_ptr() as *const u8,
            test_records.len() * std::mem::size_of::<u32>(),
        ).to_vec()
    }
}

fn bench_parse_binary_data(c: &mut Criterion) {
    let temp_dir = TempDir::new().unwrap();
    let parser = TDXDayParser::new(temp_dir.path());

    // åˆ›å»ºæµ‹è¯•æ•°æ®
    let test_data = create_test_data(&temp_dir);

    c.bench_function("parse_binary_data", |b| {
        b.iter(|| {
            let _ = parser.parse_binary_data(
                black_box(&test_data),
                black_box("600000"),
                black_box("SH")
            ).unwrap();
        })
    });
}

fn bench_parse_large_dataset(c: &mut Criterion) {
    let temp_dir = TempDir::new().unwrap();
    let parser = TDXDayParser::new(temp_dir.path());

    // åˆ›å»ºè¾ƒå¤§çš„æµ‹è¯•æ•°æ®é›†
    let mut large_data = Vec::new();
    for i in 0..10000 {  // 10000æ¡è®°å½•
        large_data.extend_from_slice(&[
            (20240101 + i).to_le_bytes(),
            1000u32.to_le_bytes(),
            1050u32.to_le_bytes(),
            980u32.to_le_bytes(),
            1020u32.to_le_bytes(),
            1040000.0f32.to_le_bytes(),
            1000000u32.to_le_bytes(),
            0u32.to_le_bytes(),
        ]);
    }

    c.bench_function("parse_large_dataset", |b| {
        b.iter(|| {
            let _ = parser.parse_binary_data(
                black_box(&large_data),
                black_box("600000"),
                black_box("SH")
            ).unwrap();
        })
    });
}

criterion_group!(
    benches,
    bench_parse_binary_data,
    bench_parse_large_dataset
);
criterion_main!(benches);
```

### 3. è¿è¡Œæµ‹è¯•

```bash
# è¿›å…¥é¡¹ç›®æ ¹ç›®å½•
cd /home/jackluo/data/PulseTrader

# ç¡®ä¿Rustç¯å¢ƒ
rustc --version
cargo --version

# è¿è¡Œæµ‹è¯•
cd rust
cargo test

# è¿è¡ŒåŸºå‡†æµ‹è¯•
cargo bench

# æ„å»ºåº“
cargo build --release
```

---

## ğŸ¯ æœ¬èŠ‚å°ç»“

### âœ… å®Œæˆå†…å®¹

1. **é€šè¾¾ä¿¡æ•°æ®æ ¼å¼åˆ†æ**: è¯¦ç»†è§£æäº†dayæ–‡ä»¶çš„äºŒè¿›åˆ¶ç»“æ„
2. **Rustè§£æå™¨å®ç°**: åˆ›å»ºäº†é«˜æ€§èƒ½çš„äºŒè¿›åˆ¶æ•°æ®è§£æå™¨
3. **æ•°æ®éªŒè¯æœºåˆ¶**: å®ç°äº†å®Œå–„çš„æ•°æ®éªŒè¯å’Œé”™è¯¯å¤„ç†
4. **å·¥å…·æ¨¡å—**: æä¾›äº†æ–‡ä»¶å¤„ç†ã€å‹ç¼©ã€éªŒè¯ç­‰å·¥å…·å‡½æ•°
5. **ä¸‹è½½å·¥å…·**: å®ç°äº†é€šè¾¾ä¿¡æ•°æ®è‡ªåŠ¨ä¸‹è½½è„šæœ¬

### ğŸ“Š æ ¸å¿ƒç‰¹æ€§

1. **é›¶æ‹·è´è§£æ**: ç›´æ¥æ“ä½œå­—èŠ‚æ•°ç»„ï¼Œé¿å…ä¸å¿…è¦çš„å†…å­˜åˆ†é…
2. **å¹¶è¡Œå¤„ç†**: åŸºäºRustçš„æ‰€æœ‰æƒç³»ç»Ÿå®ç°å®‰å…¨çš„æ•°æ®å¹¶è¡Œå¤„ç†
3. **ç±»å‹å®‰å…¨**: ç¼–è¯‘æ—¶ç±»å‹æ£€æŸ¥ï¼Œé¿å…è¿è¡Œæ—¶é”™è¯¯
4. **å†…å­˜å®‰å…¨**: Rustçš„å†…å­˜å®‰å…¨ä¿è¯ï¼Œé˜²æ­¢ç¼“å†²åŒºæº¢å‡ºç­‰é—®é¢˜
5. **é«˜æ€§èƒ½**: å……åˆ†åˆ©ç”¨ç³»ç»Ÿèµ„æºï¼Œå®ç°æœ€ä¼˜çš„è§£ææ€§èƒ½

### ğŸ”§ æ•°æ®æ ¼å¼è¦ç‚¹

- **æ–‡ä»¶å¤§å°**: æ¯æ¡æ—¥çº¿è®°å½•32å­—èŠ‚ï¼Œç´§å‡‘å­˜å‚¨
- **ä»·æ ¼ç²¾åº¦**: ä»·æ ¼ä»¥åˆ†ä¸ºå•ä½å­˜å‚¨ï¼Œéœ€è¦é™¤ä»¥100è½¬æ¢ä¸ºå…ƒ
- **æ—¥æœŸæ ¼å¼**: 32ä½æ•´æ•°ï¼Œæ ¼å¼ä¸ºYYYYMMDD
- **æ•°æ®éªŒè¯**: åŒ…å«ä»·æ ¼åˆç†æ€§æ£€æŸ¥å’Œæ ¼å¼éªŒè¯

### âš ï¸ æ³¨æ„äº‹é¡¹

1. **å­—èŠ‚åº**: é€šè¾¾ä¿¡æ•°æ®ä½¿ç”¨å°ç«¯å­—èŠ‚åº
2. **æ–‡ä»¶ç¼–ç **: æ–‡ä»¶åä½¿ç”¨ASCIIç¼–ç 
3. **æ•°æ®èŒƒå›´**: æ³¨æ„ä»·æ ¼å’Œæˆäº¤é‡çš„åˆç†èŒƒå›´æ£€æŸ¥
4. **é”™è¯¯å¤„ç†**: äºŒè¿›åˆ¶æ•°æ®è§£æéœ€è¦ä¸¥æ ¼çš„é”™è¯¯å¤„ç†
5. **å†…å­˜ç®¡ç†**: å¤§æ–‡ä»¶è§£ææ—¶æ³¨æ„å†…å­˜ä½¿ç”¨ä¼˜åŒ–

### ğŸ”„ ä¸‹ä¸€æ­¥

ä¸‹ä¸€èŠ‚æˆ‘ä»¬å°†å­¦ä¹ **Rusté«˜æ€§èƒ½æ•°æ®å¤„ç†**ï¼Œå®ç°å¹¶è¡Œå¤„ç†å’Œå†…å­˜ä¼˜åŒ–ç­–ç•¥ã€‚

**[â†’ å‰å¾€ 2.2 Rusté«˜æ€§èƒ½æ•°æ®å¤„ç†](2.2-Rusté«˜æ€§èƒ½æ•°æ®å¤„ç†.md)**

---

## ğŸ†˜ å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### Q1: é€šè¾¾ä¿¡æ•°æ®æ–‡ä»¶ä»å“ªé‡Œè·å–ï¼Ÿ

**A**: è·å–æ–¹å¼ï¼š
1. å®˜æ–¹ä¸‹è½½ï¼šhttps://data.tdx.com.cn/vipdoc/hsjday.zip
2. å®šæœŸæ›´æ–°ï¼šéœ€è¦å®šæœŸä¸‹è½½æœ€æ–°çš„æ•°æ®åŒ…
3. å¤‡ä»½ç­–ç•¥ï¼šå»ºè®®ä¿ç•™å†å²æ•°æ®æ–‡ä»¶ä»¥å¤‡æ¢å¤

### Q2: Rustè§£æå™¨å¦‚ä½•å¤„ç†å¤§æ•°æ®æ–‡ä»¶ï¼Ÿ

**A**: ä¼˜åŒ–ç­–ç•¥ï¼š
1. åˆ†å—è¯»å–ï¼šé¿å…ä¸€æ¬¡æ€§åŠ è½½æ•´ä¸ªæ–‡ä»¶åˆ°å†…å­˜
2. æµå¼å¤„ç†ï¼šè¾¹è¯»å–è¾¹è§£æï¼Œå‡å°‘å†…å­˜å ç”¨
3. å¹¶è¡Œå¤„ç†ï¼šä½¿ç”¨Rayonè¿›è¡Œå¹¶è¡Œæ•°æ®å¤„ç†
4. å†…å­˜æ˜ å°„ï¼šå¯¹äºè¶…å¤§æ–‡ä»¶ä½¿ç”¨å†…å­˜æ˜ å°„

### Q3: æ•°æ®æ ¼å¼å‘ç”Ÿå˜åŒ–æ€ä¹ˆåŠï¼Ÿ

**A**: åº”å¯¹ç­–ç•¥ï¼š
1. ç‰ˆæœ¬æ£€æµ‹ï¼šåœ¨æ–‡ä»¶å¤´æ·»åŠ ç‰ˆæœ¬æ ‡è¯†
2. å…¼å®¹æ€§å¤„ç†ï¼šæ”¯æŒå¤šä¸ªç‰ˆæœ¬çš„è§£æé€»è¾‘
3. è‡ªåŠ¨é™çº§ï¼šæ— æ³•è§£ææ—¶å°è¯•æ—§ç‰ˆæœ¬æ ¼å¼
4. æ›´æ–°é€šçŸ¥ï¼šæ£€æµ‹åˆ°æ ¼å¼å˜åŒ–æ—¶å‘å‡ºè­¦å‘Š

### Q4: å¦‚ä½•å¤„ç†æŸåçš„æ•°æ®æ–‡ä»¶ï¼Ÿ

**A**: å¤„ç†æ–¹æ³•ï¼š
1. æ–‡ä»¶æ ¡éªŒï¼šä½¿ç”¨CRCæˆ–MD5æ ¡éªŒæ–‡ä»¶å®Œæ•´æ€§
2. è®°å½•è·³è¿‡ï¼šé‡åˆ°æŸåè®°å½•æ—¶è·³è¿‡å¹¶è®°å½•
3. éƒ¨åˆ†æ¢å¤ï¼šå°è¯•æ¢å¤å¯è¯»å–çš„æ•°æ®
4. é‡æ–°ä¸‹è½½ï¼šæ£€æµ‹åˆ°é—®é¢˜æ—¶è‡ªåŠ¨é‡æ–°ä¸‹è½½

---

**æœ¬èŠ‚å»ºç«‹äº†åšå®çš„é€šè¾¾ä¿¡æ•°æ®è§£æåŸºç¡€ï¼Œä¸ºé«˜æ€§èƒ½æ•°æ®å¤„ç†å¥ å®šäº†é‡è¦åŸºç¡€ï¼** ğŸš€âœ¨
