# 2.1 Akshareæ•°æ®æ¥å£é›†æˆ

## ğŸ“– æœ¬èŠ‚æ¦‚è¿°

æœ¬èŠ‚å°†è¯¦ç»†ä»‹ç»å¦‚ä½•é›†æˆAkshareæ•°æ®æ¥å£ï¼Œæ„å»ºAè‚¡æ•°æ®é‡‡é›†ç³»ç»Ÿçš„åŸºç¡€æ¶æ„ã€‚Akshareæ˜¯ä¸“é—¨ä¸ºå›½å†…é‡‘èæ•°æ®è®¾è®¡çš„å¼€æºæ•°æ®æ¥å£åº“ï¼Œæä¾›äº†ä¸°å¯Œçš„Aè‚¡æ•°æ®è·å–åŠŸèƒ½ã€‚

## ğŸ¯ å­¦ä¹ ç›®æ ‡

å®Œæˆæœ¬èŠ‚å­¦ä¹ åï¼Œæ‚¨å°†èƒ½å¤Ÿï¼š
- âœ… å®‰è£…å’Œé…ç½®Akshareåº“
- âœ… è·å–Aè‚¡åŸºç¡€ä¿¡æ¯æ•°æ®
- âœ… å®æ—¶è¡Œæƒ…æ•°æ®é‡‡é›†
- âœ… å†å²Kçº¿æ•°æ®æ‰¹é‡ä¸‹è½½
- âœ… å¤„ç†APIè°ƒç”¨é¢‘ç‡é™åˆ¶

## â±ï¸ é¢„è®¡æ—¶é—´ï¼š30-40åˆ†é’Ÿ

---

## ğŸ”§ ç¯å¢ƒå‡†å¤‡

### 1. æ£€æŸ¥å½“å‰ç¯å¢ƒ

é¦–å…ˆç¡®ä¿æ‚¨å·²ç»å®Œæˆäº†ç¬¬ä¸€ç« çš„ç¯å¢ƒæ­å»ºï¼š

```bash
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source .venv/bin/activate

# æ£€æŸ¥Pythonç‰ˆæœ¬
python --version  # åº”è¯¥æ˜¾ç¤º Python 3.12.x

# æ£€æŸ¥ClickHouseæœåŠ¡çŠ¶æ€
docker-compose ps
```

### 2. éªŒè¯Akshareå®‰è£…

```bash
# æ£€æŸ¥akshareæ˜¯å¦å·²å®‰è£…
python -c "import akshare as ak; print(f'Akshareç‰ˆæœ¬: {ak.__version__}')"
```

å¦‚æœæœªå®‰è£…ï¼Œè¯·æ‰§è¡Œï¼š

```bash
# å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„akshare
.venv/bin/pip install akshare --upgrade
```

---

## ğŸ“Š AkshareåŸºç¡€é…ç½®

### 1. åˆ›å»ºæ•°æ®é‡‡é›†å™¨åŸºç±»

åˆ›å»º `src/data/collectors/base_collector.py`ï¼š

```python
"""
åŸºç¡€æ•°æ®é‡‡é›†å™¨
æä¾›ç»Ÿä¸€çš„Akshareæ¥å£è°ƒç”¨å’Œé”™è¯¯å¤„ç†æœºåˆ¶
"""

import time
import logging
from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional, Union
import akshare as ak
import pandas as pd
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)


class BaseCollector(ABC):
    """æ•°æ®é‡‡é›†å™¨åŸºç±»"""

    def __init__(self, max_retries: int = 3, delay: float = 1.0):
        """
        åˆå§‹åŒ–é‡‡é›†å™¨

        Args:
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            delay: è¯·æ±‚é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.max_retries = max_retries
        self.delay = delay
        self.last_request_time = 0

    def _rate_limit(self):
        """è¯·æ±‚é¢‘ç‡é™åˆ¶"""
        current_time = time.time()
        elapsed = current_time - self.last_request_time

        if elapsed < self.delay:
            sleep_time = self.delay - elapsed
            logger.debug(f"è¯·æ±‚é¢‘ç‡é™åˆ¶ï¼Œç­‰å¾… {sleep_time:.2f} ç§’")
            time.sleep(sleep_time)

        self.last_request_time = time.time()

    def _call_api(self, func, *args, **kwargs) -> Optional[pd.DataFrame]:
        """
        å®‰å…¨è°ƒç”¨Akshare API

        Args:
            func: Akshareå‡½æ•°
            *args: ä½ç½®å‚æ•°
            **kwargs: å…³é”®å­—å‚æ•°

        Returns:
            DataFrameæˆ–Noneï¼ˆå¦‚æœå¤±è´¥ï¼‰
        """
        self._rate_limit()

        for attempt in range(self.max_retries):
            try:
                logger.debug(f"è°ƒç”¨API: {func.__name__}, å°è¯•æ¬¡æ•°: {attempt + 1}")

                # è°ƒç”¨API
                result = func(*args, **kwargs)

                # éªŒè¯ç»“æœ
                if isinstance(result, pd.DataFrame):
                    if result.empty:
                        logger.warning(f"APIè¿”å›ç©ºæ•°æ®: {func.__name__}")
                        return pd.DataFrame()

                    logger.info(f"æˆåŠŸè·å–æ•°æ®: {len(result)} è¡Œ x {len(result.columns)} åˆ—")
                    return result
                else:
                    logger.error(f"APIè¿”å›éDataFrameç±»å‹: {type(result)}")
                    return pd.DataFrame()

            except Exception as e:
                logger.error(f"APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{self.max_retries}): {e}")

                if attempt < self.max_retries - 1:
                    # æŒ‡æ•°é€€é¿ç­–ç•¥
                    wait_time = self.delay * (2 ** attempt)
                    logger.info(f"ç­‰å¾… {wait_time:.2f} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    logger.error(f"APIè°ƒç”¨æœ€ç»ˆå¤±è´¥: {func.__name__}")
                    return None

        return None

    @abstractmethod
    def collect(self, **kwargs) -> Optional[pd.DataFrame]:
        """æŠ½è±¡æ–¹æ³•ï¼šå­ç±»å¿…é¡»å®ç°æ•°æ®é‡‡é›†é€»è¾‘"""
        pass

    def save_data(self, data: pd.DataFrame, filepath: str) -> bool:
        """
        ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶

        Args:
            data: è¦ä¿å­˜çš„æ•°æ®
            filepath: æ–‡ä»¶è·¯å¾„

        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            data.to_csv(filepath, index=False, encoding='utf-8-sig')
            logger.info(f"æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
            return True
        except Exception as e:
            logger.error(f"ä¿å­˜æ•°æ®å¤±è´¥: {e}")
            return False
```

### 2. åˆ›å»ºè‚¡ç¥¨ä¿¡æ¯é‡‡é›†å™¨

åˆ›å»º `src/data/collectors/stock_info.py`ï¼š

```python
"""
è‚¡ç¥¨åŸºç¡€ä¿¡æ¯é‡‡é›†å™¨
è·å–Aè‚¡è‚¡ç¥¨åˆ—è¡¨ã€åŸºç¡€ä¿¡æ¯ç­‰æ•°æ®
"""

import pandas as pd
import akshare as ak
from datetime import datetime
from typing import Optional, List
import logging

from .base_collector import BaseCollector

logger = logging.getLogger(__name__)


class StockInfoCollector(BaseCollector):
    """è‚¡ç¥¨åŸºç¡€ä¿¡æ¯é‡‡é›†å™¨"""

    def __init__(self, delay: float = 2.0):
        super().__init__(delay=delay)

    def collect_stock_list(self) -> Optional[pd.DataFrame]:
        """
        è·å–Aè‚¡è‚¡ç¥¨åˆ—è¡¨

        Returns:
            è‚¡ç¥¨åˆ—è¡¨DataFrame
        """
        logger.info("å¼€å§‹è·å–Aè‚¡è‚¡ç¥¨åˆ—è¡¨...")

        # è·å–æ²ªå¸‚è‚¡ç¥¨åˆ—è¡¨
        sh_stocks = self._call_api(ak.stock_info_a_code_name)
        if sh_stocks is not None:
            sh_stocks['market'] = 'SH'
            sh_stocks['exchange'] = 'ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€'

        # è·å–æ·±å¸‚è‚¡ç¥¨åˆ—è¡¨
        sz_stocks = self._call_api(ak.stock_info_a_code_name)
        if sz_stocks is not None:
            sz_stocks['market'] = 'SZ'
            sz_stocks['exchange'] = 'æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€'

        # åˆå¹¶æ•°æ®ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…éœ€è¦åˆ†åˆ«è·å–ï¼‰
        all_stocks = sh_stocks if sh_stocks is not None else pd.DataFrame()

        if not all_stocks.empty:
            # æ ‡å‡†åŒ–åˆ—å
            if 'code' in all_stocks.columns and 'name' in all_stocks.columns:
                all_stocks = all_stocks.rename(columns={
                    'code': 'symbol',
                    'name': 'stock_name'
                })

            # æ·»åŠ é‡‡é›†æ—¶é—´
            all_stocks['collected_at'] = datetime.now()
            all_stocks['is_active'] = 1

            logger.info(f"æˆåŠŸè·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œå…± {len(all_stocks)} åªè‚¡ç¥¨")

        return all_stocks

    def collect_stock_detail(self, symbol: str) -> Optional[pd.DataFrame]:
        """
        è·å–å•åªè‚¡ç¥¨è¯¦ç»†ä¿¡æ¯

        Args:
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯DataFrame
        """
        logger.info(f"è·å–è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯: {symbol}")

        # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        stock_info = self._call_api(ak.stock_individual_info_em, symbol=symbol)

        if stock_info is not None and not stock_info.empty:
            # æ·»åŠ è‚¡ç¥¨ä»£ç 
            stock_info['symbol'] = symbol
            stock_info['collected_at'] = datetime.now()

            # è½¬ç½®æ•°æ®ï¼Œä½¿itemåˆ—ä¸ºå­—æ®µå
            if 'item' in stock_info.columns and 'value' in stock_info.columns:
                stock_info = stock_info.set_index('item')['value'].to_frame().T
                stock_info['symbol'] = symbol
                stock_info['collected_at'] = datetime.now()

        return stock_info

    def collect_industry_stocks(self, industry_name: str) -> Optional[pd.DataFrame]:
        """
        è·å–è¡Œä¸šè‚¡ç¥¨åˆ—è¡¨

        Args:
            industry_name: è¡Œä¸šåç§°

        Returns:
            è¡Œä¸šè‚¡ç¥¨åˆ—è¡¨DataFrame
        """
        logger.info(f"è·å–è¡Œä¸šè‚¡ç¥¨åˆ—è¡¨: {industry_name}")

        # è¿™é‡Œä½¿ç”¨æ¦‚å¿µè‚¡æ¿å—æ¥å£ä½œä¸ºç¤ºä¾‹
        concept_stocks = self._call_api(ak.stock_board_concept_cons_em, symbol=industry_name)

        if concept_stocks is not None:
            concept_stocks['industry'] = industry_name
            concept_stocks['collected_at'] = datetime.now()

        return concept_stocks

    def collect(self, data_type: str = "stock_list", **kwargs) -> Optional[pd.DataFrame]:
        """
        ç»Ÿä¸€æ•°æ®é‡‡é›†æ¥å£

        Args:
            data_type: æ•°æ®ç±»å‹
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            é‡‡é›†çš„æ•°æ®
        """
        if data_type == "stock_list":
            return self.collect_stock_list()
        elif data_type == "stock_detail":
            symbol = kwargs.get('symbol')
            if not symbol:
                logger.error("è·å–è‚¡ç¥¨è¯¦æƒ…éœ€è¦æä¾›symbolå‚æ•°")
                return None
            return self.collect_stock_detail(symbol)
        elif data_type == "industry_stocks":
            industry = kwargs.get('industry_name')
            if not industry:
                logger.error("è·å–è¡Œä¸šè‚¡ç¥¨éœ€è¦æä¾›industry_nameå‚æ•°")
                return None
            return self.collect_industry_stocks(industry)
        else:
            logger.error(f"ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {data_type}")
            return None


def test_stock_info_collector():
    """æµ‹è¯•è‚¡ç¥¨ä¿¡æ¯é‡‡é›†å™¨"""
    collector = StockInfoCollector()

    print("=== æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨è·å– ===")
    stock_list = collector.collect_stock_list()
    if stock_list is not None:
        print(f"è·å–åˆ° {len(stock_list)} åªè‚¡ç¥¨")
        print(stock_list.head())

    print("\n=== æµ‹è¯•ä¸ªè‚¡è¯¦æƒ…è·å– ===")
    if stock_list is not None and len(stock_list) > 0:
        sample_symbol = stock_list.iloc[0]['symbol']
        detail = collector.collect_stock_detail(sample_symbol)
        if detail is not None:
            print(f"è‚¡ç¥¨ {sample_symbol} è¯¦æƒ…:")
            print(detail.head())


if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO)

    # è¿è¡Œæµ‹è¯•
    test_stock_info_collector()
```

### 3. åˆ›å»ºå®æ—¶è¡Œæƒ…é‡‡é›†å™¨

åˆ›å»º `src/data/collectors/realtime.py`ï¼š

```python
"""
å®æ—¶è¡Œæƒ…æ•°æ®é‡‡é›†å™¨
è·å–Aè‚¡å®æ—¶æŠ¥ä»·ã€åˆ†æ—¶æ•°æ®ç­‰
"""

import pandas as pd
import akshare as ak
from datetime import datetime, time
from typing import Optional, List, Dict
import logging

from .base_collector import BaseCollector

logger = logging.getLogger(__name__)


class RealtimeCollector(BaseCollector):
    """å®æ—¶è¡Œæƒ…æ•°æ®é‡‡é›†å™¨"""

    def __init__(self, delay: float = 0.5):
        super().__init__(delay=delay)

    def is_trading_time(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºäº¤æ˜“æ—¶é—´"""
        now = datetime.now().time()

        # Aè‚¡äº¤æ˜“æ—¶é—´
        morning_start = time(9, 30)
        morning_end = time(11, 30)
        afternoon_start = time(13, 0)
        afternoon_end = time(15, 0)

        return ((morning_start <= now <= morning_end) or
                (afternoon_start <= now <= afternoon_end))

    def collect_realtime_quote(self, symbol: str) -> Optional[pd.DataFrame]:
        """
        è·å–ä¸ªè‚¡å®æ—¶è¡Œæƒ…

        Args:
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            å®æ—¶è¡Œæƒ…æ•°æ®
        """
        if not self.is_trading_time():
            logger.warning(f"éäº¤æ˜“æ—¶é—´ï¼Œè·³è¿‡å®æ—¶è¡Œæƒ…è·å–: {symbol}")
            return pd.DataFrame()

        logger.info(f"è·å–å®æ—¶è¡Œæƒ…: {symbol}")

        # ä½¿ç”¨Akshareè·å–å®æ—¶è¡Œæƒ…
        realtime_data = self._call_api(ak.stock_zh_a_spot_em)

        if realtime_data is not None:
            # ç­›é€‰æŒ‡å®šè‚¡ç¥¨
            if 'ä»£ç ' in realtime_data.columns:
                stock_data = realtime_data[realtime_data['ä»£ç '] == symbol]
                if not stock_data.empty:
                    # æ·»åŠ æ—¶é—´æˆ³
                    stock_data['timestamp'] = datetime.now()
                    stock_data['symbol'] = symbol
                    logger.info(f"è·å–åˆ°å®æ—¶è¡Œæƒ…: {symbol}")
                    return stock_data

        return pd.DataFrame()

    def collect_batch_quotes(self, symbols: List[str]) -> Optional[pd.DataFrame]:
        """
        æ‰¹é‡è·å–å®æ—¶è¡Œæƒ…

        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨

        Returns:
            æ‰¹é‡è¡Œæƒ…æ•°æ®
        """
        if not self.is_trading_time():
            logger.warning("éäº¤æ˜“æ—¶é—´ï¼Œè·³è¿‡æ‰¹é‡å®æ—¶è¡Œæƒ…è·å–")
            return pd.DataFrame()

        logger.info(f"æ‰¹é‡è·å–å®æ—¶è¡Œæƒ…: {len(symbols)} åªè‚¡ç¥¨")

        # è·å–å…¨å¸‚åœºå®æ—¶è¡Œæƒ…
        all_quotes = self._call_api(ak.stock_zh_a_spot_em)

        if all_quotes is not None and not all_quotes.empty:
            # ç­›é€‰ç›®æ ‡è‚¡ç¥¨
            if 'ä»£ç ' in all_quotes.columns:
                filtered_quotes = all_quotes[all_quotes['ä»£ç '].isin(symbols)]

                if not filtered_quotes.empty:
                    # æ·»åŠ æ—¶é—´æˆ³å’Œæ ‡å‡†åŒ–åˆ—å
                    filtered_quotes['timestamp'] = datetime.now()
                    filtered_quotes['symbol'] = filtered_quotes['ä»£ç ']
                    filtered_quotes['stock_name'] = filtered_quotes['åç§°']

                    logger.info(f"è·å–åˆ° {len(filtered_quotes)} åªè‚¡ç¥¨çš„å®æ—¶è¡Œæƒ…")
                    return filtered_quotes

        return pd.DataFrame()

    def collect_intraday_data(self, symbol: str, period: str = "1") -> Optional[pd.DataFrame]:
        """
        è·å–åˆ†æ—¶æ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            period: å‘¨æœŸï¼Œ1=1åˆ†é’Ÿï¼Œ5=5åˆ†é’Ÿ

        Returns:
            åˆ†æ—¶æ•°æ®
        """
        if not self.is_trading_time() and period == "1":
            logger.warning(f"éäº¤æ˜“æ—¶é—´ï¼Œåˆ†é’Ÿçº¿æ•°æ®å¯èƒ½ä¸å®Œæ•´: {symbol}")

        logger.info(f"è·å–åˆ†æ—¶æ•°æ®: {symbol}, å‘¨æœŸ: {period}åˆ†é’Ÿ")

        # ä½¿ç”¨Akshareè·å–åˆ†é’ŸKçº¿æ•°æ®
        if period == "1":
            intraday_data = self._call_api(ak.stock_zh_a_hist_min_em, symbol=symbol, period="1", adjust="qfq")
        elif period == "5":
            intraday_data = self._call_api(ak.stock_zh_a_hist_min_em, symbol=symbol, period="5", adjust="qfq")
        else:
            logger.error(f"ä¸æ”¯æŒçš„å‘¨æœŸ: {period}")
            return None

        if intraday_data is not None and not intraday_data.empty:
            # æ·»åŠ è‚¡ç¥¨ä»£ç 
            intraday_data['symbol'] = symbol
            intraday_data['period'] = period
            intraday_data['collected_at'] = datetime.now()

            # æ ‡å‡†åŒ–åˆ—åï¼ˆæ ¹æ®å®é™…è¿”å›çš„åˆ—åè°ƒæ•´ï¼‰
            column_mapping = {
                'æ—¶é—´': 'datetime',
                'å¼€ç›˜': 'open',
                'æ”¶ç›˜': 'close',
                'æœ€é«˜': 'high',
                'æœ€ä½': 'low',
                'æˆäº¤é‡': 'volume',
                'æˆäº¤é¢': 'amount'
            }

            # åº”ç”¨åˆ—åæ˜ å°„ï¼ˆå­˜åœ¨çš„åˆ—æ‰æ˜ å°„ï¼‰
            for old_name, new_name in column_mapping.items():
                if old_name in intraday_data.columns:
                    intraday_data[new_name] = intraday_data[old_name]

            logger.info(f"è·å–åˆ° {len(intraday_data)} æ¡åˆ†æ—¶æ•°æ®")

        return intraday_data

    def collect_market_overview(self) -> Optional[pd.DataFrame]:
        """
        è·å–å¸‚åœºæ¦‚è§ˆæ•°æ®

        Returns:
            å¸‚åœºæ¦‚è§ˆä¿¡æ¯
        """
        logger.info("è·å–å¸‚åœºæ¦‚è§ˆæ•°æ®")

        # è·å–ä¸Šè¯æŒ‡æ•°
        sh_index = self._call_api(ak.stock_zh_index_spot_em, symbol="ä¸Šè¯æŒ‡æ•°")

        # è·å–æ·±è¯æˆæŒ‡
        sz_index = self._call_api(ak.stock_zh_index_spot_em, symbol="æ·±è¯æˆæŒ‡")

        # è·å–åˆ›ä¸šæ¿æŒ‡
        cyb_index = self._call_api(ak.stock_zh_index_spot_em, symbol="åˆ›ä¸šæ¿æŒ‡")

        market_data = []

        for index_name, index_data in [
            ("ä¸Šè¯æŒ‡æ•°", sh_index),
            ("æ·±è¯æˆæŒ‡", sz_index),
            ("åˆ›ä¸šæ¿æŒ‡", cyb_index)
        ]:
            if index_data is not None and not index_data.empty:
                index_info = {
                    'index_name': index_name,
                    'timestamp': datetime.now(),
                    'collected_at': datetime.now()
                }

                # æå–å…³é”®ä¿¡æ¯ï¼ˆæ ¹æ®å®é™…è¿”å›çš„åˆ—è°ƒæ•´ï¼‰
                if 'æœ€æ–°ä»·' in index_data.columns:
                    index_info['latest_price'] = index_data['æœ€æ–°ä»·'].iloc[0]
                if 'æ¶¨è·Œé¢' in index_data.columns:
                    index_info['change_amount'] = index_data['æ¶¨è·Œé¢'].iloc[0]
                if 'æ¶¨è·Œå¹…' in index_data.columns:
                    index_info['change_percent'] = index_data['æ¶¨è·Œå¹…'].iloc[0]

                market_data.append(index_info)

        if market_data:
            return pd.DataFrame(market_data)

        return pd.DataFrame()

    def collect(self, data_type: str = "realtime_quote", **kwargs) -> Optional[pd.DataFrame]:
        """
        ç»Ÿä¸€æ•°æ®é‡‡é›†æ¥å£

        Args:
            data_type: æ•°æ®ç±»å‹
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            é‡‡é›†çš„æ•°æ®
        """
        if data_type == "realtime_quote":
            symbol = kwargs.get('symbol')
            if not symbol:
                logger.error("è·å–å®æ—¶è¡Œæƒ…éœ€è¦æä¾›symbolå‚æ•°")
                return None
            return self.collect_realtime_quote(symbol)

        elif data_type == "batch_quotes":
            symbols = kwargs.get('symbols', [])
            if not symbols:
                logger.error("æ‰¹é‡è·å–è¡Œæƒ…éœ€è¦æä¾›symbolså‚æ•°")
                return None
            return self.collect_batch_quotes(symbols)

        elif data_type == "intraday":
            symbol = kwargs.get('symbol')
            if not symbol:
                logger.error("è·å–åˆ†æ—¶æ•°æ®éœ€è¦æä¾›symbolå‚æ•°")
                return None
            period = kwargs.get('period', '1')
            return self.collect_intraday_data(symbol, period)

        elif data_type == "market_overview":
            return self.collect_market_overview()

        else:
            logger.error(f"ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {data_type}")
            return None


def test_realtime_collector():
    """æµ‹è¯•å®æ—¶è¡Œæƒ…é‡‡é›†å™¨"""
    collector = RealtimeCollector()

    print("=== æµ‹è¯•å¸‚åœºæ¦‚è§ˆ ===")
    overview = collector.collect_market_overview()
    if overview is not None:
        print(overview)

    print("\n=== æµ‹è¯•ä¸ªè‚¡å®æ—¶è¡Œæƒ… ===")
    # æµ‹è¯•ä¸€äº›çŸ¥åè‚¡ç¥¨
    test_symbols = ['000001', '000002', '600000']
    for symbol in test_symbols:
        quote = collector.collect_realtime_quote(symbol)
        if quote is not None and not quote.empty:
            print(f"{symbol} å®æ—¶è¡Œæƒ…è·å–æˆåŠŸ")
        else:
            print(f"{symbol} å®æ—¶è¡Œæƒ…è·å–å¤±è´¥æˆ–éäº¤æ˜“æ—¶é—´")


if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO)

    # è¿è¡Œæµ‹è¯•
    test_realtime_collector()
```

---

## ğŸ“ˆ åˆ›å»ºå†å²æ•°æ®é‡‡é›†å™¨

åˆ›å»º `src/data/collectors/historical.py`ï¼š

```python
"""
å†å²æ•°æ®é‡‡é›†å™¨
è·å–Aè‚¡å†å²Kçº¿ã€è´¢åŠ¡æ•°æ®ç­‰
"""

import pandas as pd
import akshare as ak
from datetime import datetime, timedelta
from typing import Optional, List, Dict
import logging

from .base_collector import BaseCollector

logger = logging.getLogger(__name__)


class HistoricalCollector(BaseCollector):
    """å†å²æ•°æ®é‡‡é›†å™¨"""

    def __init__(self, delay: float = 1.0):
        super().__init__(delay=delay)

    def collect_daily_kline(self, symbol: str, start_date: str = None, end_date: str = None,
                           adjust: str = "qfq") -> Optional[pd.DataFrame]:
        """
        è·å–æ—¥çº¿å†å²æ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
            end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
            adjust: å¤æƒæ–¹å¼ï¼Œqfqå‰å¤æƒï¼Œhfqåå¤æƒï¼Œä¸å¤æƒ

        Returns:
            æ—¥çº¿æ•°æ®DataFrame
        """
        if not end_date:
            end_date = datetime.now().strftime('%Y%m%d')

        if not start_date:
            # é»˜è®¤è·å–æœ€è¿‘ä¸€å¹´çš„æ•°æ®
            start_date = (datetime.now() - timedelta(days=365)).strftime('%Y%m%d')

        logger.info(f"è·å–æ—¥çº¿æ•°æ®: {symbol}, {start_date} ~ {end_date}, å¤æƒ: {adjust}")

        # ä½¿ç”¨Akshareè·å–å†å²æ•°æ®
        historical_data = self._call_api(
            ak.stock_zh_a_hist,
            symbol=symbol,
            start_date=start_date,
            end_date=end_date,
            adjust=adjust
        )

        if historical_data is not None and not historical_data.empty:
            # æ·»åŠ å…ƒæ•°æ®
            historical_data['symbol'] = symbol
            historical_data['adjust_type'] = adjust
            historical_data['data_source'] = 'akshare'
            historical_data['collected_at'] = datetime.now()

            # æ ‡å‡†åŒ–åˆ—å
            column_mapping = {
                'æ—¥æœŸ': 'date',
                'å¼€ç›˜': 'open',
                'æ”¶ç›˜': 'close',
                'æœ€é«˜': 'high',
                'æœ€ä½': 'low',
                'æˆäº¤é‡': 'volume',
                'æˆäº¤é¢': 'amount',
                'æŒ¯å¹…': 'amplitude',
                'æ¶¨è·Œå¹…': 'change_percent',
                'æ¶¨è·Œé¢': 'change_amount',
                'æ¢æ‰‹ç‡': 'turnover'
            }

            # åº”ç”¨åˆ—åæ˜ å°„
            for old_name, new_name in column_mapping.items():
                if old_name in historical_data.columns:
                    historical_data[new_name] = historical_data[old_name]

            logger.info(f"è·å–åˆ° {len(historical_data)} æ¡æ—¥çº¿æ•°æ®")

        return historical_data

    def collect_weekly_kline(self, symbol: str, start_date: str = None,
                           end_date: str = None, adjust: str = "qfq") -> Optional[pd.DataFrame]:
        """
        è·å–å‘¨çº¿å†å²æ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            adjust: å¤æƒæ–¹å¼

        Returns:
            å‘¨çº¿æ•°æ®DataFrame
        """
        logger.info(f"è·å–å‘¨çº¿æ•°æ®: {symbol}")

        # Akshareçš„å‘¨çº¿æ•°æ®æ¥å£
        weekly_data = self._call_api(
            ak.stock_zh_a_hist,
            symbol=symbol,
            start_date=start_date,
            end_date=end_date,
            adjust=adjust,
            period="weekly"
        )

        if weekly_data is not None and not weekly_data.empty:
            weekly_data['symbol'] = symbol
            weekly_data['period'] = 'weekly'
            weekly_data['adjust_type'] = adjust
            weekly_data['collected_at'] = datetime.now()

        return weekly_data

    def collect_financial_data(self, symbol: str) -> Optional[pd.DataFrame]:
        """
        è·å–è´¢åŠ¡æ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            è´¢åŠ¡æ•°æ®DataFrame
        """
        logger.info(f"è·å–è´¢åŠ¡æ•°æ®: {symbol}")

        # è·å–ä¸»è¦è´¢åŠ¡æŒ‡æ ‡
        financial_indicators = self._call_api(
            ak.stock_financial_analysis_indicator,
            symbol=symbol
        )

        if financial_indicators is not None and not financial_indicators.empty:
            financial_indicators['symbol'] = symbol
            financial_indicators['collected_at'] = datetime.now()

        return financial_indicators

    def collect_batch_historical(self, symbols: List[str], start_date: str = None,
                               end_date: str = None, adjust: str = "qfq") -> Dict[str, pd.DataFrame]:
        """
        æ‰¹é‡è·å–å†å²æ•°æ®

        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            adjust: å¤æƒæ–¹å¼

        Returns:
            è‚¡ç¥¨ä»£ç åˆ°æ•°æ®çš„æ˜ å°„
        """
        logger.info(f"æ‰¹é‡è·å–å†å²æ•°æ®: {len(symbols)} åªè‚¡ç¥¨")

        results = {}

        for i, symbol in enumerate(symbols):
            try:
                logger.info(f"å¤„ç†è¿›åº¦: {i+1}/{len(symbols)} - {symbol}")

                data = self.collect_daily_kline(symbol, start_date, end_date, adjust)
                if data is not None and not data.empty:
                    results[symbol] = data
                else:
                    logger.warning(f"è·å–å†å²æ•°æ®å¤±è´¥: {symbol}")

                # æ‰¹é‡è·å–æ—¶å¢åŠ é—´éš”
                if i < len(symbols) - 1:
                    time.sleep(self.delay)

            except Exception as e:
                logger.error(f"è·å–å†å²æ•°æ®å¼‚å¸¸ {symbol}: {e}")
                continue

        logger.info(f"æ‰¹é‡è·å–å®Œæˆï¼ŒæˆåŠŸ: {len(results)}/{len(symbols)}")
        return results

    def collect_stock_dividends(self, symbol: str) -> Optional[pd.DataFrame]:
        """
        è·å–è‚¡ç¥¨åˆ†çº¢æ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            åˆ†çº¢æ•°æ®DataFrame
        """
        logger.info(f"è·å–åˆ†çº¢æ•°æ®: {symbol}")

        # è·å–åˆ†çº¢æ•°æ®
        dividend_data = self._call_api(ak.stock_dividend_cninfo, symbol=symbol)

        if dividend_data is not None and not dividend_data.empty:
            dividend_data['symbol'] = symbol
            dividend_data['collected_at'] = datetime.now()

        return dividend_data

    def collect(self, data_type: str = "daily_kline", **kwargs) -> Optional[pd.DataFrame]:
        """
        ç»Ÿä¸€æ•°æ®é‡‡é›†æ¥å£

        Args:
            data_type: æ•°æ®ç±»å‹
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            é‡‡é›†çš„æ•°æ®
        """
        if data_type == "daily_kline":
            symbol = kwargs.get('symbol')
            if not symbol:
                logger.error("è·å–æ—¥çº¿æ•°æ®éœ€è¦æä¾›symbolå‚æ•°")
                return None
            return self.collect_daily_kline(
                symbol,
                kwargs.get('start_date'),
                kwargs.get('end_date'),
                kwargs.get('adjust', 'qfq')
            )

        elif data_type == "weekly_kline":
            symbol = kwargs.get('symbol')
            if not symbol:
                logger.error("è·å–å‘¨çº¿æ•°æ®éœ€è¦æä¾›symbolå‚æ•°")
                return None
            return self.collect_weekly_kline(
                symbol,
                kwargs.get('start_date'),
                kwargs.get('end_date'),
                kwargs.get('adjust', 'qfq')
            )

        elif data_type == "financial_data":
            symbol = kwargs.get('symbol')
            if not symbol:
                logger.error("è·å–è´¢åŠ¡æ•°æ®éœ€è¦æä¾›symbolå‚æ•°")
                return None
            return self.collect_financial_data(symbol)

        elif data_type == "dividends":
            symbol = kwargs.get('symbol')
            if not symbol:
                logger.error("è·å–åˆ†çº¢æ•°æ®éœ€è¦æä¾›symbolå‚æ•°")
                return None
            return self.collect_stock_dividends(symbol)

        elif data_type == "batch_historical":
            symbols = kwargs.get('symbols', [])
            if not symbols:
                logger.error("æ‰¹é‡è·å–å†å²æ•°æ®éœ€è¦æä¾›symbolså‚æ•°")
                return None
            results = self.collect_batch_historical(
                symbols,
                kwargs.get('start_date'),
                kwargs.get('end_date'),
                kwargs.get('adjust', 'qfq')
            )
            # è¿”å›ç¬¬ä¸€ä¸ªç»“æœä½œä¸ºç¤ºä¾‹ï¼Œå®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦ä¸åŒçš„å¤„ç†æ–¹å¼
            return list(results.values())[0] if results else pd.DataFrame()

        else:
            logger.error(f"ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {data_type}")
            return None


def test_historical_collector():
    """æµ‹è¯•å†å²æ•°æ®é‡‡é›†å™¨"""
    collector = HistoricalCollector()

    print("=== æµ‹è¯•æ—¥çº¿æ•°æ®è·å– ===")
    # æµ‹è¯•è·å–å¹³å®‰é“¶è¡Œçš„å†å²æ•°æ®
    daily_data = collector.collect_daily_kline("000001", "20240101", "20241201")
    if daily_data is not None:
        print(f"è·å–åˆ° {len(daily_data)} æ¡æ—¥çº¿æ•°æ®")
        print(daily_data.head())
        print(f"åˆ—å: {list(daily_data.columns)}")

    print("\n=== æµ‹è¯•è´¢åŠ¡æ•°æ®è·å– ===")
    financial_data = collector.collect_financial_data("000001")
    if financial_data is not None:
        print(f"è·å–åˆ° {len(financial_data)} æ¡è´¢åŠ¡æ•°æ®")
        print(financial_data.head())


if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO)

    # è¿è¡Œæµ‹è¯•
    test_historical_collector()
```

---

## ğŸ§ª æµ‹è¯•æ•°æ®é‡‡é›†å™¨

### 1. åˆ›å»ºæµ‹è¯•è„šæœ¬

åˆ›å»º `scripts/test_data_collection.py`ï¼š

```python
#!/usr/bin/env python3
"""
æ•°æ®é‡‡é›†åŠŸèƒ½æµ‹è¯•è„šæœ¬
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.data.collectors.stock_info import StockInfoCollector
from src.data.collectors.realtime import RealtimeCollector
from src.data.collectors.historical import HistoricalCollector
import logging
from datetime import datetime

def main():
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    print("ğŸš€ å¼€å§‹æµ‹è¯•æ•°æ®é‡‡é›†åŠŸèƒ½...\n")

    # 1. æµ‹è¯•è‚¡ç¥¨ä¿¡æ¯é‡‡é›†å™¨
    print("=== 1. æµ‹è¯•è‚¡ç¥¨ä¿¡æ¯é‡‡é›†å™¨ ===")
    info_collector = StockInfoCollector()

    try:
        stock_list = info_collector.collect_stock_list()
        if stock_list is not None and not stock_list.empty:
            print(f"âœ… æˆåŠŸè·å–è‚¡ç¥¨åˆ—è¡¨: {len(stock_list)} åªè‚¡ç¥¨")
            print(f"   åˆ—å: {list(stock_list.columns)}")
            print(f"   ç¤ºä¾‹æ•°æ®:\n{stock_list.head(3)}")
        else:
            print("âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥")
    except Exception as e:
        print(f"âŒ è‚¡ç¥¨ä¿¡æ¯é‡‡é›†å™¨æµ‹è¯•å¼‚å¸¸: {e}")

    print()

    # 2. æµ‹è¯•å®æ—¶è¡Œæƒ…é‡‡é›†å™¨
    print("=== 2. æµ‹è¯•å®æ—¶è¡Œæƒ…é‡‡é›†å™¨ ===")
    realtime_collector = RealtimeCollector()

    try:
        # æµ‹è¯•å¸‚åœºæ¦‚è§ˆ
        market_overview = realtime_collector.collect_market_overview()
        if market_overview is not None and not market_overview.empty:
            print(f"âœ… æˆåŠŸè·å–å¸‚åœºæ¦‚è§ˆ: {len(market_overview)} ä¸ªæŒ‡æ•°")
            print(f"   æ•°æ®:\n{market_overview}")
        else:
            print("âŒ è·å–å¸‚åœºæ¦‚è§ˆå¤±è´¥")
    except Exception as e:
        print(f"âŒ å®æ—¶è¡Œæƒ…é‡‡é›†å™¨æµ‹è¯•å¼‚å¸¸: {e}")

    print()

    # 3. æµ‹è¯•å†å²æ•°æ®é‡‡é›†å™¨
    print("=== 3. æµ‹è¯•å†å²æ•°æ®é‡‡é›†å™¨ ===")
    historical_collector = HistoricalCollector()

    try:
        # æµ‹è¯•è·å–å¹³å®‰é“¶è¡Œæœ€è¿‘ä¸€ä¸ªæœˆçš„æ•°æ®
        end_date = datetime.now().strftime('%Y%m%d')
        start_date = (datetime.now().replace(day=1) - timedelta(days=1)).strftime('%Y%m%d')  # ä¸Šä¸ªæœˆç¬¬ä¸€å¤©

        daily_data = historical_collector.collect_daily_kline("000001", start_date, end_date)
        if daily_data is not None and not daily_data.empty:
            print(f"âœ… æˆåŠŸè·å–å†å²æ•°æ®: {len(daily_data)} æ¡è®°å½•")
            print(f"   æ•°æ®æ—¶é—´èŒƒå›´: {daily_data['date'].min()} ~ {daily_data['date'].max()}")
            print(f"   åˆ—å: {list(daily_data.columns)}")
        else:
            print("âŒ è·å–å†å²æ•°æ®å¤±è´¥")
    except Exception as e:
        print(f"âŒ å†å²æ•°æ®é‡‡é›†å™¨æµ‹è¯•å¼‚å¸¸: {e}")

    print("\nğŸ‰ æ•°æ®é‡‡é›†åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    main()
```

### 2. è¿è¡Œæµ‹è¯•

```bash
# ç¡®ä¿è™šæ‹Ÿç¯å¢ƒæ¿€æ´»
source .venv/bin/activate

# è¿è¡Œæµ‹è¯•è„šæœ¬
python scripts/test_data_collection.py
```

---

## ğŸ“ é…ç½®æ–‡ä»¶

### 1. åˆ›å»ºæ•°æ®æºé…ç½®

åˆ›å»º `config/data_sources.yaml`ï¼š

```yaml
# æ•°æ®æºé…ç½®æ–‡ä»¶

akshare:
  # APIè°ƒç”¨é…ç½®
  timeout: 30          # è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
  max_retries: 3       # æœ€å¤§é‡è¯•æ¬¡æ•°
  delay: 1.0          # è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰

  # æ•°æ®ç±»å‹é…ç½®
  data_types:
    stock_info:
      enabled: true
      update_interval: "1d"      # æ›´æ–°é¢‘ç‡
      retry_on_error: true

    realtime:
      enabled: true
      update_interval: "10s"     # å®æ—¶æ•°æ®æ›´æ–°é¢‘ç‡
      trading_hours_only: true   # ä»…äº¤æ˜“æ—¶é—´è·å–

    historical:
      enabled: true
      update_interval: "1d"      # å†å²æ•°æ®æ›´æ–°é¢‘ç‡
      batch_size: 50            # æ‰¹é‡è·å–æ•°é‡
      max_days_per_request: 365 # å•æ¬¡è¯·æ±‚æœ€å¤§å¤©æ•°

    financial:
      enabled: true
      update_interval: "1d"
      quarterly_update: true    # å­£åº¦æ›´æ–°

# æ•°æ®å­˜å‚¨é…ç½®
storage:
  clickhouse:
    batch_size: 1000           # æ‰¹é‡æ’å…¥å¤§å°
    connection_timeout: 30     # è¿æ¥è¶…æ—¶

  cache:
    redis:
      ttl: 3600              # ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
      max_memory: "100MB"     # æœ€å¤§å†…å­˜ä½¿ç”¨

# é”™è¯¯å¤„ç†é…ç½®
error_handling:
  max_consecutive_errors: 5   # æœ€å¤§è¿ç»­é”™è¯¯æ¬¡æ•°
  error_backoff_factor: 2     # é”™è¯¯é€€é¿å› å­
  notification_enabled: false # é”™è¯¯é€šçŸ¥å¼€å…³
```

---

## ğŸ¯ æœ¬èŠ‚å°ç»“

### âœ… å®Œæˆå†…å®¹

1. **åŸºç¡€æ¶æ„**: åˆ›å»ºäº†ç»Ÿä¸€çš„æ•°æ®é‡‡é›†å™¨åŸºç±»ï¼Œæä¾›APIè°ƒç”¨ã€é”™è¯¯å¤„ç†ã€é¢‘ç‡é™åˆ¶ç­‰åŠŸèƒ½
2. **è‚¡ç¥¨ä¿¡æ¯é‡‡é›†å™¨**: å®ç°äº†Aè‚¡åŸºç¡€ä¿¡æ¯ã€ä¸ªè‚¡è¯¦æƒ…ã€è¡Œä¸šè‚¡ç¥¨ç­‰æ•°æ®è·å–
3. **å®æ—¶è¡Œæƒ…é‡‡é›†å™¨**: å®ç°äº†ä¸ªè‚¡å®æ—¶æŠ¥ä»·ã€æ‰¹é‡è¡Œæƒ…ã€åˆ†æ—¶æ•°æ®ã€å¸‚åœºæ¦‚è§ˆç­‰åŠŸèƒ½
4. **å†å²æ•°æ®é‡‡é›†å™¨**: å®ç°äº†æ—¥çº¿ã€å‘¨çº¿ã€è´¢åŠ¡æ•°æ®ã€åˆ†çº¢ä¿¡æ¯ç­‰å†å²æ•°æ®è·å–
5. **æµ‹è¯•æ¡†æ¶**: åˆ›å»ºäº†å®Œæ•´çš„æµ‹è¯•è„šæœ¬æ¥éªŒè¯å„é‡‡é›†å™¨åŠŸèƒ½

### ğŸ“Š æ•°æ®æ¥å£è¦†ç›–

| æ•°æ®ç±»å‹ | Akshareæ¥å£ | çŠ¶æ€ | è¯´æ˜ |
|---------|-------------|------|------|
| è‚¡ç¥¨åˆ—è¡¨ | stock_info_a_code_name | âœ… | è·å–Aè‚¡æ‰€æœ‰è‚¡ç¥¨ä»£ç  |
| å®æ—¶è¡Œæƒ… | stock_zh_a_spot_em | âœ… | å®æ—¶æŠ¥ä»·æ•°æ® |
| åˆ†é’ŸKçº¿ | stock_zh_a_hist_min_em | âœ… | åˆ†æ—¶Kçº¿æ•°æ® |
| æ—¥çº¿æ•°æ® | stock_zh_a_hist | âœ… | å†å²æ—¥çº¿æ•°æ® |
| è´¢åŠ¡æ•°æ® | stock_financial_analysis_indicator | âœ… | è´¢åŠ¡æŒ‡æ ‡æ•°æ® |
| å¸‚åœºæŒ‡æ•° | stock_zh_index_spot_em | âœ… | ä¸»è¦æŒ‡æ•°è¡Œæƒ… |

### âš ï¸ æ³¨æ„äº‹é¡¹

1. **APIé™åˆ¶**: Akshareæœ‰è°ƒç”¨é¢‘ç‡é™åˆ¶ï¼Œè¯·åˆç†è®¾ç½®è¯·æ±‚é—´éš”
2. **äº¤æ˜“æ—¶é—´**: å®æ—¶æ•°æ®ä»…åœ¨äº¤æ˜“æ—¶é—´æœ‰æ•ˆï¼Œéäº¤æ˜“æ—¶é—´ä¼šè·å–ç©ºæ•°æ®
3. **ç½‘ç»œç¯å¢ƒ**: ç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®šï¼Œå¿…è¦æ—¶è€ƒè™‘ä½¿ç”¨ä»£ç†
4. **æ•°æ®è´¨é‡**: å»ºè®®å®æ–½æ•°æ®éªŒè¯æœºåˆ¶ï¼Œç¡®ä¿æ•°æ®å‡†ç¡®æ€§

### ğŸ”„ ä¸‹ä¸€æ­¥

ä¸‹ä¸€èŠ‚æˆ‘ä»¬å°†å­¦ä¹ **æ•°æ®æ¸…æ´—ä¸éªŒè¯**ï¼Œç¡®ä¿é‡‡é›†åˆ°çš„æ•°æ®è´¨é‡ç¬¦åˆé‡åŒ–äº¤æ˜“çš„è¦æ±‚ã€‚

**[â†’ å‰å¾€ 2.2 æ•°æ®æ¸…æ´—ä¸éªŒè¯](2.2-æ•°æ®æ¸…æ´—ä¸éªŒè¯.md)**

---

## ğŸ†˜ å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### Q1: Akshare APIè°ƒç”¨å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**A**: æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
1. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸
2. Akshareç‰ˆæœ¬æ˜¯å¦éœ€è¦æ›´æ–°ï¼š`pip install akshare --upgrade`
3. æŸ¥çœ‹Akshareå®˜æ–¹æ–‡æ¡£æ˜¯å¦æœ‰æ¥å£å˜æ›´
4. å¢åŠ è¯·æ±‚é—´éš”æ—¶é—´ï¼Œé¿å…è§¦å‘é¢‘ç‡é™åˆ¶

### Q2: å®æ—¶æ•°æ®è¿”å›ç©ºæ€ä¹ˆåŠï¼Ÿ

**A**: å¯èƒ½çš„åŸå› ï¼š
1. éäº¤æ˜“æ—¶é—´ï¼šAè‚¡äº¤æ˜“æ—¶é—´ä¸º 9:30-11:30, 13:00-15:00
2. è‚¡ç¥¨ä»£ç é”™è¯¯ï¼šç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„6ä½æ•°å­—ä»£ç 
3. è‚¡ç¥¨åœç‰Œï¼šæ£€æŸ¥ç›®æ ‡è‚¡ç¥¨æ˜¯å¦æ­£å¸¸äº¤æ˜“

### Q3: å†å²æ•°æ®è·å–é€Ÿåº¦æ…¢æ€ä¹ˆåŠï¼Ÿ

**A**: ä¼˜åŒ–å»ºè®®ï¼š
1. å‡å°‘å•æ¬¡è¯·æ±‚çš„æ—¶é—´èŒƒå›´
2. ä½¿ç”¨æ‰¹é‡è·å–æ¥å£
3. åˆç†è®¾ç½®è¯·æ±‚é—´éš”
4. è€ƒè™‘ä½¿ç”¨å¤šçº¿ç¨‹ï¼ˆæ³¨æ„ä¸è¦è¶…è¿‡APIé™åˆ¶ï¼‰

### Q4: æ•°æ®æ ¼å¼ä¸ç»Ÿä¸€æ€ä¹ˆåŠï¼Ÿ

**A**: è§£å†³æ–¹æ¡ˆï¼š
1. æŸ¥çœ‹Akshareè¿”å›çš„åŸå§‹æ•°æ®ç»“æ„
2. æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´åˆ—åæ˜ å°„
3. å®æ–½æ•°æ®æ ‡å‡†åŒ–å¤„ç†ï¼ˆä¸‹ä¸€èŠ‚è¯¦ç»†ä»‹ç»ï¼‰

---

**æœ¬èŠ‚ä¸ºåç»­çš„æ•°æ®å­˜å‚¨å’Œåˆ†æå¥ å®šäº†é‡è¦åŸºç¡€ï¼Œç¡®ä¿æ‚¨èƒ½å¤Ÿå¯é åœ°è·å–å„ç§Aè‚¡å¸‚åœºæ•°æ®ï¼** ğŸ“ˆâœ¨
